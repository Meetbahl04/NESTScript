{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10313743,"sourceType":"datasetVersion","datasetId":6384944},{"sourceId":10316712,"sourceType":"datasetVersion","datasetId":6386990},{"sourceId":10318147,"sourceType":"datasetVersion","datasetId":6388050},{"sourceId":10324019,"sourceType":"datasetVersion","datasetId":6392093},{"sourceId":10324061,"sourceType":"datasetVersion","datasetId":6392126},{"sourceId":10347347,"sourceType":"datasetVersion","datasetId":6407383}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\ndf_1 = pd.read_csv('/kaggle/input/nest-dataset-ps-1/Problem Statements and Data Sets/usecase_1_.csv')\ndf_2 = df = pd.read_excel('/kaggle/input/nest-dataset-ps-1/Problem Statements and Data Sets/usecase_4_.xlsx', sheet_name='ctg-studies')\ndf_3 = pd.read_csv('/kaggle/input/nest-dataset-ps-1/Problem Statements and Data Sets/usecase_3_.csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_1.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_2.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_3.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df_1, df_2, and df_3 are already loaded\n\n# Concatenate the dataframes vertically\ncombined_df = pd.concat([df_1, df_2, df_3], ignore_index=True)\n\n# Rename 'NCT Number' to 'nct_id'\ncombined_df.rename(columns={'NCT Number': 'nct_id'}, inplace=True)\n\ncombined_df.tail() # To see the output, run the code.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Read the eligibilities.txt file with the correct separator and chunksize\neligibilities_iter = pd.read_csv('/kaggle/input/nest-dataset-ps-1/Problem Statements and Data Sets/eligibilities.txt', sep='|', chunksize=50000)\n\n# Initialize an empty list to store processed chunks\nall_chunks = []\n\n# Process the eligibilities.txt file in chunks\nfor chunk in eligibilities_iter:\n    all_chunks.append(chunk)\n\n# Combine all processed chunks\ndf_elig = pd.concat(all_chunks, ignore_index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_elig.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\n\n# Merge the dataframes on 'nct_id' using an inner join\ndf_4 = pd.merge(combined_df, df_elig, on='nct_id', how='inner')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_4.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# columns present in df_1 but not in df_4\ncols_in_df1_not_df4 = set(df_1.columns) - set(df_4.columns)\n\n# columns present in df_4 but not in df_1\ncols_in_df4_not_df1 = set(df_4.columns) - set(df_1.columns)\n\nprint(\"Columns in df_1 but not in df_4:\", cols_in_df1_not_df4)\nprint(\"Columns in df_4 but not in df_1:\", cols_in_df4_not_df1)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df_4[['nct_id', 'Study Title', 'Primary Outcome Measures', 'Secondary Outcome Measures', 'criteria', 'Funder Type']]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for missing values in each column of the DataFrame 'df'\nmissing_values_count = df.isnull().sum()\nmissing_values_count","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df.copy()  # Ensure df is a standalone DataFrame\n\n# analyzing the text length for different columns, these text lengths include spaces as well.\ntext_columns = ['Study Title', 'Primary Outcome Measures', 'Secondary Outcome Measures', 'criteria']\nfor col in text_columns:\n    df.loc[:, f'{col}_length'] = df[col].apply(lambda x: len(str(x)))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nprint(np.mean(df['Study Title_length']))\nprint(np.mean(df['Primary Outcome Measures_length']))\nprint(np.mean(df['Secondary Outcome Measures_length']))\nprint(np.mean(df['criteria_length']))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\n\ndef count_special_chars(text):\n    if pd.isna(text):  # Handle missing values\n        return 0\n    # Define a regex pattern to match specific special characters\n    # Add or remove characters as needed\n    special_char_pattern = r'[!@#$%^&*()_+{}\\[\\]:;\"\\'<>,.?/\\\\|`~\\-=]'\n    return len(re.findall(special_char_pattern, text))\n\n# Columns to check for special characters\ncolumns_to_check = ['Study Title', 'Primary Outcome Measures', 'Secondary Outcome Measures', 'criteria']\n\n# Iterate over the specified columns and count special characters\nspecial_char_counts = {}\nfor column in columns_to_check:\n    special_char_counts[column] = df[column].apply(count_special_chars).sum()\n\n# Print the results\nfor column, count in special_char_counts.items():\n    print(f\"Column '{column}' has {count} special characters.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nimport pandas as pd\nfrom typing import Dict\n\n# Medical abbreviations dictionary\nmedical_abbreviations = {\n    'htn': 'hypertension',\n    'mi': 'myocardial infarction',\n    't2dm': 'type 2 diabetes mellitus',\n    'aki': 'acute kidney injury',\n    'aep': 'alcohol-exposed pregnancy',\n    'bmi': 'body mass index',\n    'allo': 'allogeneic',\n    'aebp': 'alcohol exposure biomarker positive',\n    'crp': 'c-reactive protein',\n    'ckd': 'chronic kidney disease',\n    'cvd': 'cardiovascular disease',\n    'dm': 'diabetes mellitus',\n    'hba1c': 'glycated hemoglobin',\n    'hf': 'heart failure',\n    'pae': 'potential alcohol exposure',\n    'sae': 'serious adverse event',\n    'sbp': 'systolic blood pressure',\n    'dbp': 'diastolic blood pressure',\n    # Add more abbreviations as needed\n}\n\ndef standardize_units(text: str) -> str:\n    \"\"\"Standardize numerical values and units.\"\"\"\n    text = re.sub(r'(\\d+)\\s*years?', r'\\1 year', text, flags=re.IGNORECASE)\n    text = re.sub(r'(\\d+)\\s*days?', r'\\1 day', text, flags=re.IGNORECASE)\n    text = re.sub(r'(\\d+)\\s*weeks?', r'\\1 week', text, flags=re.IGNORECASE)\n    text = re.sub(r'(\\d+)\\s*months?', r'\\1 month', text, flags=re.IGNORECASE)\n    return text\n\ndef expand_abbreviations(text: str, abbrev_dict: Dict[str, str]) -> str:\n    \"\"\"Expand medical abbreviations to their full forms.\"\"\"\n    for abbrev, full_form in abbrev_dict.items():\n        text = re.sub(r'\\b' + abbrev + r'\\b', full_form, text)\n    return text\n\ndef preprocess_text(text: str) -> str:\n    \"\"\"\n    Comprehensive text preprocessing function.\n    \"\"\"\n    if pd.isna(text) or str(text).strip() == '':\n        return \"\"\n    \n    # Convert to string and lowercase\n    text = str(text).lower()\n    \n    # Preserve numerical values with units before general cleaning\n    text = standardize_units(text)\n    \n    # Remove HTML tags if any\n    text = re.sub(r'<.*?>', '', text)\n    \n    # Handle bullet points and lists\n    text = re.sub(r'[\\n\\r]+', ' ', text)  # Replace newlines with space\n    text = re.sub(r'[â€¢\\-*]+', '', text)   # Remove bullet points\n    \n    # Expand medical abbreviations\n    text = expand_abbreviations(text, medical_abbreviations)\n    \n    # Remove special characters but preserve numbers and units\n    text = re.sub(r'[^a-z0-9\\s]', ' ', text)\n    \n    # Handle multiple spaces\n    text = re.sub(r'\\s+', ' ', text)\n    \n    return text.strip()\n\ndef process_dataframe(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Process the entire dataframe.\n    \"\"\"\n    columns_to_process = ['Study Title', 'Primary Outcome Measures', 'Secondary Outcome Measures', 'criteria']\n    \n    # Add missing value flags\n    df['Secondary_Outcome_Missing'] = df['Secondary Outcome Measures'].isna().astype(int)\n    df['Primary_Outcome_Missing'] = df['Primary Outcome Measures'].isna().astype(int)\n    \n    # Preprocess and add cleaned text columns\n    for column in columns_to_process:\n        print(f\"Processing {column}...\")\n        df[column + '_Cleaned'] = df[column].apply(preprocess_text)\n    \n    # Create new DataFrame with necessary columns\n    new_columns = ['nct_id'] + \\\n                 [col + '_Cleaned' for col in columns_to_process] + \\\n                 ['Secondary_Outcome_Missing', 'Primary_Outcome_Missing']\n    \n    return df[new_columns]\n\n# Main execution\nif __name__ == \"__main__\":\n    processed_df = process_dataframe(df)\n    processed_df.to_csv('clinical_trials_cleaned.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Most of the data is cleaned. now basically gotta work towards the missing values.","metadata":{}},{"cell_type":"code","source":"import pandas as pd","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nest-ps-1-cleaned/clinical_trials_cleaned.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"missing_values = df.isnull().sum()\nprint(missing_values)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom typing import Dict, List\n\ndef handle_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n    \"\"\"\n    Comprehensive missing value handling based on the proposed strategy\n    \"\"\"\n    # Create a copy to avoid modifying original\n    processed_df = df.copy()\n    \n    # 1. Secondary Outcome Measures (High missing rate)\n    # We already have Secondary_Outcome_Missing flag\n    # Replace missing values with standardized text\n    processed_df['Secondary Outcome Measures_Cleaned'] = processed_df['Secondary Outcome Measures_Cleaned'].fillna('no secondary outcomes provided')\n    \n    # 2. Primary Outcome Measures (Moderate missing rate)\n    # Create flag for missing primary outcomes\n    processed_df['Primary_Outcome_Missing'] = processed_df['Primary Outcome Measures_Cleaned'].isna().astype(int)\n    \n    # Replace missing values with standardized text\n    # We're using a placeholder here - in the next phase, we can implement similar-trial imputation\n    processed_df['Primary Outcome Measures_Cleaned'] = processed_df['Primary Outcome Measures_Cleaned'].fillna('primary outcome not specified')\n    \n    # 3. Criteria (Low missing rate)\n    # Create flag for missing criteria\n    processed_df['Criteria_Missing'] = processed_df['criteria_Cleaned'].isna().astype(int)\n    \n    # Replace missing values with standardized text\n    processed_df['criteria_Cleaned'] = processed_df['criteria_Cleaned'].fillna('no criteria provided')\n    \n    # 4. Create a data completeness score\n    processed_df['completeness_score'] = 1.0\n    # Reduce score for missing values\n    processed_df.loc[processed_df['Secondary_Outcome_Missing'] == 1, 'completeness_score'] -= 0.2\n    processed_df.loc[processed_df['Primary_Outcome_Missing'] == 1, 'completeness_score'] -= 0.4\n    processed_df.loc[processed_df['Criteria_Missing'] == 1, 'completeness_score'] -= 0.4\n    \n    return processed_df\n\ndef generate_missing_data_report(original_df: pd.DataFrame, processed_df: pd.DataFrame) -> None:\n    \"\"\"\n    Generate a detailed report of missing data handling\n    \"\"\"\n    print(\"Missing Data Report\")\n    print(\"-\" * 50)\n    \n    # Original missing values\n    print(\"\\nOriginal Missing Values:\")\n    for column in original_df.columns:\n        missing_count = original_df[column].isna().sum()\n        total_count = len(original_df)\n        missing_percentage = (missing_count / total_count) * 100\n        print(f\"{column}: {missing_count} missing ({missing_percentage:.2f}%)\")\n    \n    # Processed missing values\n    print(\"\\nProcessed Missing Values:\")\n    for column in processed_df.columns:\n        missing_count = processed_df[column].isna().sum()\n        total_count = len(processed_df)\n        missing_percentage = (missing_count / total_count) * 100\n        print(f\"{column}: {missing_count} missing ({missing_percentage:.2f}%)\")\n    \n    # Completeness score statistics\n    print(\"\\nCompleteness Score Statistics:\")\n    print(f\"Mean: {processed_df['completeness_score'].mean():.2f}\")\n    print(f\"Median: {processed_df['completeness_score'].median():.2f}\")\n    print(f\"Min: {processed_df['completeness_score'].min():.2f}\")\n    print(f\"Max: {processed_df['completeness_score'].max():.2f}\")\n\n# Main execution\nif __name__ == \"__main__\":\n    # Process the dataframe\n    processed_df = handle_missing_values(df)\n    \n    # Generate report\n    generate_missing_data_report(df, processed_df)\n    \n    # Save processed dataframe\n    processed_df.to_csv('clinical_trials_processed_with_missing_handled.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"processed_df.tail()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Since the data cleaning is done now. We are moving on to processing and converting our data to embeddings.","metadata":{}},{"cell_type":"code","source":"!pip install sentence-transformers\n!pip install scikit-learn\n!pip install transformers\n!pip install torch\n!pip install pandas\n!pip install numpy","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom transformers import AutoTokenizer, AutoModel\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom typing import List, Dict","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/nest-ps-1-data-cleaning-done/clinical_trials_processed_with_missing_handled.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sentence_transformers import SentenceTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport torch\nimport numpy as np\nfrom typing import List, Dict\nfrom tqdm.auto import tqdm\nimport time\nimport psutil\nimport gc\nimport os\n\ndef get_memory_usage():\n    process = psutil.Process()\n    memory_use = process.memory_info().rss / (1024 ** 2)  # in MB\n    return memory_use\n\nclass TrialEncoder:\n    def __init__(self, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        self.device = device\n        print(f\"Using device: {self.device}\")\n        print(f\"Memory before loading SBERT model: {get_memory_usage():.2f} MB\")\n        \n        # Load model with optimizations\n        self.sbert_model = SentenceTransformer('pritamdeka/S-PubMedBert-MS-MARCO')\n        \n        # Convert to half precision if using CUDA\n        if self.device == 'cuda':\n            self.sbert_model.half()  # Use FP16 for faster processing\n        \n        self.sbert_model.to(self.device)\n        print(f\"Memory after loading SBERT model: {get_memory_usage():.2f} MB\")\n        \n        # Initialize TF-IDF with optimized parameters\n        self.tfidf = TfidfVectorizer(\n            max_features=10000, \n            stop_words='english',\n            dtype=np.float32  # Use float32 instead of float64 for memory efficiency\n        )\n    \n    def combine_text_fields(self, row: pd.Series) -> str:\n        return (f\"TITLE: {row['Study Title_Cleaned']} \"\n                f\"PRIMARY: {row['Primary Outcome Measures_Cleaned']} \"\n                f\"SECONDARY: {row['Secondary Outcome Measures_Cleaned']} \"\n                f\"CRITERIA: {row['criteria_Cleaned']}\")\n\n    @torch.cuda.amp.autocast()  # Enable automatic mixed precision\n    def encode_sbert(self, texts: List[str]) -> np.ndarray:\n        return self.sbert_model.encode(\n            texts,\n            show_progress_bar=True,\n            device=self.device,\n            batch_size=256,  # Increased batch size for better GPU utilization\n            normalize_embeddings=True,\n            convert_to_numpy=True\n        )\n    \n    def encode_tfidf(self, texts: List[str]) -> np.ndarray:\n        return self.tfidf.fit_transform(texts).astype(np.float32).toarray()\n\ndef process_in_chunks(df: pd.DataFrame, chunk_size: int = 5000, save_path: str = './embeddings/') -> None:\n    os.makedirs(save_path, exist_ok=True)\n    \n    # Initialize encoder\n    encoder = TrialEncoder()\n    total_chunks = len(df) // chunk_size + (1 if len(df) % chunk_size != 0 else 0)\n    \n    # Initialize arrays and progress bar\n    all_sbert = []\n    all_tfidf = []\n    \n    # Main progress bar\n    with tqdm(total=total_chunks, desc=\"Processing chunks\", position=0) as chunk_pbar:\n        try:\n            for chunk_idx in range(total_chunks):\n                start_idx = chunk_idx * chunk_size\n                end_idx = min((chunk_idx + 1) * chunk_size, len(df))\n                \n                # Update progress description\n                chunk_pbar.set_description(\n                    f\"Chunk {chunk_idx + 1}/{total_chunks} [Rows {start_idx}-{end_idx}]\"\n                )\n                \n                # Process chunk\n                chunk_df = df.iloc[start_idx:end_idx]\n                \n                # Combine texts efficiently\n                combined_texts = [\n                    encoder.combine_text_fields(row) \n                    for _, row in tqdm(chunk_df.iterrows(), \n                                     desc=\"Combining texts\", \n                                     position=1, \n                                     leave=False)\n                ]\n                \n                # Generate embeddings\n                sbert_embeddings = encoder.encode_sbert(combined_texts)\n                all_sbert.append(sbert_embeddings)\n                \n                tfidf_vectors = encoder.encode_tfidf(combined_texts)\n                all_tfidf.append(tfidf_vectors)\n                \n                # Clear memory\n                del combined_texts, sbert_embeddings, tfidf_vectors\n                gc.collect()\n                torch.cuda.empty_cache()\n                \n                chunk_pbar.update(1)\n                \n                # Save backup every 5 chunks\n                if (chunk_idx + 1) % 5 == 0:\n                    timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n                    backup_path = os.path.join(save_path, 'backups')\n                    os.makedirs(backup_path, exist_ok=True)\n                    \n                    np.save(os.path.join(backup_path, f'sbert_backup_{timestamp}.npy'), \n                           np.vstack(all_sbert))\n                    np.save(os.path.join(backup_path, f'tfidf_backup_{timestamp}.npy'), \n                           np.vstack(all_tfidf))\n                    \n                    chunk_pbar.write(f\"Backup saved at chunk {chunk_idx + 1}\")\n            \n            # Save final combined embeddings\n            chunk_pbar.write(\"\\nSaving final embeddings...\")\n            timestamp = time.strftime(\"%Y%m%d-%H%M%S\")\n            \n            final_sbert = np.vstack(all_sbert)\n            np.save(os.path.join(save_path, f'sbert_embeddings_final_{timestamp}.npy'), \n                   final_sbert)\n            chunk_pbar.write(f\"Final SBERT shape: {final_sbert.shape}\")\n            del final_sbert\n            \n            final_tfidf = np.vstack(all_tfidf)\n            np.save(os.path.join(save_path, f'tfidf_vectors_final_{timestamp}.npy'), \n                   final_tfidf)\n            chunk_pbar.write(f\"Final TF-IDF shape: {final_tfidf.shape}\")\n            del final_tfidf\n            \n        except Exception as e:\n            chunk_pbar.write(f\"Error occurred: {str(e)}\")\n            raise\n\nif __name__ == \"__main__\":\n    try:\n        total_start_time = time.time()\n        print(f\"Starting processing with initial memory: {get_memory_usage():.2f} MB\")\n        \n        process_in_chunks(df, chunk_size=4000)\n        \n        total_time = time.time() - total_start_time\n        print(f\"\\nTotal execution time: {total_time/60:.2f} minutes\")\n        \n    except Exception as e:\n        print(f\"Error during processing: {str(e)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:19:29.031004Z","iopub.execute_input":"2025-01-01T05:19:29.031322Z","iopub.status.idle":"2025-01-01T05:19:29.056168Z","shell.execute_reply.started":"2025-01-01T05:19:29.031298Z","shell.execute_reply":"2025-01-01T05:19:29.054749Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-3ab29ab56415>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"],"ename":"ModuleNotFoundError","evalue":"No module named 'sentence_transformers'","output_type":"error"}],"execution_count":9},{"cell_type":"markdown","source":"### Now we are simply checking the quality of the embeddings by trying to predict the top_k titls simply using cosine similarity","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom typing import Dict, List, Tuple\nimport time\n\nclass SimilarityRetriever:\n    def __init__(self, \n                 sbert_embeddings: np.ndarray, \n                 tfidf_embeddings: np.ndarray,\n                 alpha: float = 0.7):\n        \"\"\"\n        Initialize with both types of embeddings\n        \n        Args:\n            sbert_embeddings: SBERT embeddings array\n            tfidf_embeddings: TF-IDF embeddings array\n            alpha: Weight for SBERT similarity (1-alpha for TF-IDF)\n        \"\"\"\n        # Verify and convert embeddings to float32\n        try:\n            self.sbert_embeddings = np.array(sbert_embeddings, dtype=np.float32)\n            self.tfidf_embeddings = np.array(tfidf_embeddings, dtype=np.float32)\n        except ValueError as e:\n            print(\"Error converting embeddings to float32. Please check your embedding files.\")\n            raise\n            \n        self.alpha = alpha\n        \n        # Normalize embeddings for faster cosine similarity\n        try:\n            self.sbert_normalized = self._normalize_embeddings(self.sbert_embeddings)\n            self.tfidf_normalized = self._normalize_embeddings(self.tfidf_embeddings)\n        except Exception as e:\n            print(f\"Error during normalization: {str(e)}\")\n            raise\n        \n        print(f\"Initialized with shapes: SBERT {self.sbert_embeddings.shape}, TF-IDF {self.tfidf_embeddings.shape}\")\n    \n    def _normalize_embeddings(self, embeddings: np.ndarray) -> np.ndarray:\n        \"\"\"Normalize embeddings for cosine similarity\"\"\"\n        norms = np.linalg.norm(embeddings, axis=1, keepdims=True)\n        # Avoid division by zero\n        norms[norms == 0] = 1e-10\n        return embeddings / norms\n\n# Loading and verification function\ndef load_embeddings(sbert_path: str, tfidf_path: str) -> Tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Load and verify embeddings from files\n    \n    Args:\n        sbert_path: Path to SBERT embeddings\n        tfidf_path: Path to TF-IDF embeddings\n    \n    Returns:\n        Tuple of (SBERT embeddings, TF-IDF embeddings)\n    \"\"\"\n    try:\n        print(f\"Loading SBERT embeddings from {sbert_path}\")\n        sbert = np.load(sbert_path)\n        print(f\"SBERT embeddings shape: {sbert.shape}\")\n        \n        print(f\"Loading TF-IDF embeddings from {tfidf_path}\")\n        tfidf = np.load(tfidf_path)\n        print(f\"TF-IDF embeddings shape: {tfidf.shape}\")\n        \n        # Verify data types and contents\n        if not np.issubdtype(sbert.dtype, np.number):\n            raise ValueError(f\"SBERT embeddings contain non-numeric data: {sbert.dtype}\")\n        if not np.issubdtype(tfidf.dtype, np.number):\n            raise ValueError(f\"TF-IDF embeddings contain non-numeric data: {tfidf.dtype}\")\n            \n        # Check for NaN or infinite values\n        if np.isnan(sbert).any() or np.isinf(sbert).any():\n            raise ValueError(\"SBERT embeddings contain NaN or infinite values\")\n        if np.isnan(tfidf).any() or np.isinf(tfidf).any():\n            raise ValueError(\"TF-IDF embeddings contain NaN or infinite values\")\n            \n        return sbert, tfidf\n        \n    except Exception as e:\n        print(f\"Error loading embeddings: {str(e)}\")\n        raise\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.sparse import csr_matrix\nimport torch\nfrom typing import Dict, List, Tuple\nimport time\n\nclass SimilarityRetriever:\n    def __init__(self, \n                 sbert_embeddings: np.ndarray, \n                 tfidf_embeddings: csr_matrix,\n                 alpha: float = 0.7):\n        \"\"\"\n        Initialize with both types of embeddings\n        \n        Args:\n            sbert_embeddings: SBERT embeddings array\n            tfidf_embeddings: TF-IDF embeddings sparse matrix\n            alpha: Weight for SBERT similarity (1-alpha for TF-IDF)\n        \"\"\"\n        # Verify and convert embeddings to float32\n        self.sbert_embeddings = np.array(sbert_embeddings, dtype=np.float32)\n        self.tfidf_embeddings = tfidf_embeddings.astype(np.float32)\n        \n        self.alpha = alpha\n        \n        # Normalize SBERT embeddings for cosine similarity\n        sbert_norms = np.linalg.norm(self.sbert_embeddings, axis=1, keepdims=True)\n        sbert_norms[sbert_norms == 0] = 1e-10\n        self.sbert_normalized = torch.from_numpy(self.sbert_embeddings / sbert_norms).cuda()\n        \n        # TF-IDF is kept sparse and normalized already\n        # Assuming TF-IDF is already L2 normalized; if not, normalize it\n        # For sparse matrices, assume they are normalized\n        \n        print(f\"Initialized with shapes: SBERT {self.sbert_embeddings.shape}, TF-IDF {self.tfidf_embeddings.shape}\")\n    \n    def find_similar_trials(self, query_idx: int, top_k: int = 10) -> List[Tuple[int, float]]:\n        \"\"\"\n        Find top-k most similar trials to the query trial\n        \n        Args:\n            query_idx: Index of the query trial\n            top_k: Number of top similar trials to retrieve\n        \n        Returns:\n            List of tuples (index, combined_similarity_score)\n        \"\"\"\n        # Compute SBERT similarities\n        query_sbert = self.sbert_normalized[query_idx].unsqueeze(0)\n        sbert_similarities = torch.mm(query_sbert, self.sbert_normalized.t()).squeeze()\n        sbert_similarities = sbert_similarities.cpu().numpy()\n        \n        # Compute TF-IDF similarities\n        query_tfidf = self.tfidf_embeddings[query_idx]\n        tfidf_similarities = self.tfidf_embeddings.dot(query_tfidf.T).A.flatten()\n        \n        # Combine similarities\n        combined_similarities = (self.alpha * sbert_similarities +\n                                 (1 - self.alpha) * tfidf_similarities)\n        \n        # Get top-k indices\n        top_indices = np.argsort(combined_similarities)[::-1][:top_k]\n        top_scores = combined_similarities[top_indices]\n        \n        return list(zip(top_indices, top_scores))\n    \n    def analyze_similarity_components(self, query_idx: int, trial_idx: int) -> Dict[str, float]:\n        \"\"\"\n        Analyze similarity components for a pair of trials\n        \n        Args:\n            query_idx: Index of the query trial\n            trial_idx: Index of the target trial\n        \n        Returns:\n            Dictionary with 'sbert_similarity' and 'tfidf_similarity'\n        \"\"\"\n        sbert_sim = torch.dot(self.sbert_normalized[query_idx], self.sbert_normalized[trial_idx]).item()\n        tfidf_sim = self.tfidf_embeddings[trial_idx].dot(self.tfidf_embeddings[query_idx].T).toarray()[0, 0]\n        \n        return {\n            'sbert_similarity': sbert_sim,\n            'tfidf_similarity': tfidf_sim\n        }\n\n# Loading and verification function\ndef load_embeddings(sbert_path: str, tfidf_path: str) -> Tuple[np.ndarray, csr_matrix]:\n    \"\"\"\n    Load and verify embeddings from files\n    \n    Args:\n        sbert_path: Path to SBERT embeddings\n        tfidf_path: Path to TF-IDF embeddings\n    \n    Returns:\n        Tuple of (SBERT embeddings, TF-IDF embeddings as sparse matrix)\n    \"\"\"\n    try:\n        print(f\"Loading SBERT embeddings from {sbert_path}\")\n        sbert = np.load(sbert_path)\n        print(f\"SBERT embeddings shape: {sbert.shape}\")\n        \n        print(f\"Loading TF-IDF embeddings from {tfidf_path}\")\n        tfidf_sparse = np.load(tfidf_path, allow_pickle=True)\n        tfidf = csr_matrix((tfidf_sparse['data'], \n                            tfidf_sparse['indices'], \n                            tfidf_sparse['indptr']),\n                           shape=tuple(tfidf_sparse['shape']))\n        print(f\"TF-IDF embeddings shape: {tfidf.shape}\")\n        \n        # Verify data types and contents\n        if not np.issubdtype(sbert.dtype, np.number):\n            raise ValueError(f\"SBERT embeddings contain non-numeric data: {sbert.dtype}\")\n        if not np.issubdtype(tfidf.dtype, np.number):\n            raise ValueError(f\"TF-IDF embeddings contain non-numeric data: {tfidf.dtype}\")\n            \n        # Check for NaN or infinite values\n        if np.isnan(sbert).any() or np.isinf(sbert).any():\n            raise ValueError(\"SBERT embeddings contain NaN or infinite values\")\n        if np.isnan(tfidf.data).any() or np.isinf(tfidf.data).any():\n            raise ValueError(\"TF-IDF embeddings contain NaN or infinite values\")\n            \n        return sbert, tfidf\n        \n    except Exception as e:\n        print(f\"Error loading embeddings: {str(e)}\")\n        raise\n\n# Load and check embeddings\nsbert_path = '/kaggle/input/nest-ps-1-sbert-embeddings/sbert_embeddings_final_20241228-170631.npy'\ntfidf_path = '/kaggle/input/nest-ps-1-tfidf-embeddings/tfidf_vectors_final_20241228-170631.npz'\n\nsbert, tfidf_sparse = load_embeddings(sbert_path, tfidf_path)\n\nprint(\"SBERT shape:\", sbert.shape)\nprint(\"SBERT dtype:\", sbert.dtype)\nprint(\"TF-IDF shape:\", tfidf_sparse.shape)\nprint(\"TF-IDF dtype:\", tfidf_sparse.dtype)\n\n# Now initialize the retriever with the dense arrays\nretriever = SimilarityRetriever(sbert, tfidf_sparse, alpha=0.7)\n\n# Test the retriever\nquery_idx = 0\nsimilar_trials = retriever.find_similar_trials(query_idx, top_k=10)\n\n# Print results\nprint(f\"\\nMost similar trials to trial {query_idx}:\")\nfor idx, score in similar_trials:\n    analysis = retriever.analyze_similarity_components(query_idx, idx)\n    print(f\"\\nTrial {idx}\")\n    print(f\"Combined similarity: {score:.4f}\")\n    print(f\"SBERT similarity: {analysis['sbert_similarity']:.4f}\")\n    print(f\"TF-IDF similarity: {analysis['tfidf_similarity']:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/nest-ps-1-data-cleaning-done/clinical_trials_processed_with_missing_handled.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(df['Study Title_Cleaned'][0])\nprint(df['Study Title_Cleaned'][1])\nprint(df['Study Title_Cleaned'][173809])\nprint(df['Study Title_Cleaned'][173810])\nprint(df['Study Title_Cleaned'][200735])\nprint(df['Study Title_Cleaned'][200734])\nprint(df['Study Title_Cleaned'][131525])\nprint(df['Study Title_Cleaned'][124411])\nprint(df['Study Title_Cleaned'][124412])\nprint(df['Study Title_Cleaned'][87451])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Since cosine similarity seems to be working fine. Now we are moving on to implementing multiple metrics so that we can get a better overview at things.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom scipy.sparse import csr_matrix\nimport torch\nfrom typing import Dict, List, Tuple\nimport time\n\nclass SimilarityMetrics:\n    @staticmethod\n    def euclidean_similarity(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n        \"\"\"Convert Euclidean distance to similarity score\"\"\"\n        distances = torch.cdist(x.unsqueeze(0), y, p=2).squeeze()\n        return 1 / (1 + distances)\n    \n    @staticmethod\n    def manhattan_similarity(x: torch.Tensor, y: torch.Tensor) -> torch.Tensor:\n        \"\"\"Convert Manhattan distance to similarity score\"\"\"\n        distances = torch.cdist(x.unsqueeze(0), y, p=1).squeeze()\n        return 1 / (1 + distances)\n    \n    @staticmethod\n    def sparse_euclidean_similarity(x: csr_matrix, y: csr_matrix) -> np.ndarray:\n        \"\"\"Compute Euclidean similarity for sparse matrices\"\"\"\n        # Convert query vector to dense array for operations\n        x_array = x.toarray().ravel()\n        \n        # Compute squared norms\n        x_squared = np.sum(x_array ** 2)\n        y_squared = np.asarray(y.multiply(y).sum(axis=1)).ravel()\n        \n        # Compute dot product\n        dot_product = y.dot(x.T).toarray().ravel()\n        \n        # Compute distances using broadcasting\n        distances = np.sqrt(np.maximum(x_squared + y_squared - 2 * dot_product, 0))\n        return 1 / (1 + distances)\n\n\nclass SimilarityRetriever:\n    def __init__(self, \n                 sbert_embeddings: np.ndarray, \n                 tfidf_embeddings: csr_matrix,\n                 similarity_weights: Dict[str, float] = None):\n        \"\"\"\n        Initialize with embeddings and similarity weights\n        \n        Args:\n            sbert_embeddings: SBERT embeddings array\n            tfidf_embeddings: TF-IDF embeddings sparse matrix\n            similarity_weights: Dictionary of weights for different similarity measures\n                                Default: {'cosine_sbert': 0.4, 'euclidean_sbert': 0.3, 'manhattan_sbert': 0.3,\n                                          'cosine_tfidf': 0.4, 'euclidean_tfidf': 0.6}\n        \"\"\"\n        # Set default weights if none provided\n        self.similarity_weights = similarity_weights or {\n            'cosine_sbert': 0.4,\n            'euclidean_sbert': 0.3,\n            'manhattan_sbert': 0.3,\n            'cosine_tfidf': 0.4,\n            'euclidean_tfidf': 0.6\n        }\n        \n        # Normalize weights if they do not sum to 1.0\n        if abs(sum(self.similarity_weights.values()) - 1.0) > 1e-6:\n            total = sum(self.similarity_weights.values())\n            if total == 0:\n                raise ValueError(\"Similarity weights cannot sum to zero.\")\n            self.similarity_weights = {k: v / total for k, v in self.similarity_weights.items()}\n            print(\"Weights do not sum to 1.0; normalizing them.\")\n        \n        # Initialize embeddings\n        self.sbert_embeddings = np.array(sbert_embeddings, dtype=np.float32)\n        self.tfidf_embeddings = tfidf_embeddings.astype(np.float32)\n        \n        # Normalize SBERT embeddings and move to GPU\n        sbert_norms = np.linalg.norm(self.sbert_embeddings, axis=1, keepdims=True)\n        sbert_norms[sbert_norms == 0] = 1e-10\n        self.sbert_normalized = torch.from_numpy(self.sbert_embeddings / sbert_norms).cuda()\n        \n        print(f\"Initialized with shapes: SBERT {self.sbert_embeddings.shape}, TF-IDF {self.tfidf_embeddings.shape}\")\n    \n    def compute_similarities(self, query_idx: int) -> Dict[str, np.ndarray]:\n        \"\"\"Compute all similarity measures for a query\"\"\"\n        # Get query vectors\n        query_sbert = self.sbert_normalized[query_idx].unsqueeze(0)\n        query_tfidf = self.tfidf_embeddings[query_idx]\n        \n        similarities = {}\n        \n        # SBERT similarities (GPU)\n        similarities['cosine_sbert'] = torch.mm(query_sbert, self.sbert_normalized.t()).squeeze().cpu().numpy()\n        similarities['euclidean_sbert'] = SimilarityMetrics.euclidean_similarity(\n            query_sbert, self.sbert_normalized).cpu().numpy()\n        similarities['manhattan_sbert'] = SimilarityMetrics.manhattan_similarity(\n            query_sbert, self.sbert_normalized).cpu().numpy()\n        \n        # TF-IDF similarities (CPU, sparse)\n        similarities['cosine_tfidf'] = self.tfidf_embeddings.dot(query_tfidf.T).toarray().ravel()\n        similarities['euclidean_tfidf'] = SimilarityMetrics.sparse_euclidean_similarity(\n            query_tfidf, self.tfidf_embeddings)\n        \n        return similarities\n\n\n    \n    def find_similar_trials(self, query_idx: int, top_k: int = 10) -> List[Tuple[int, float, Dict[str, float]]]:\n        \"\"\"\n        Find top-k most similar trials using ensemble of similarity measures\n        \n        Returns:\n            List of tuples (index, combined_score, individual_scores)\n        \"\"\"\n        # Compute all similarities\n        similarities = self.compute_similarities(query_idx)\n        \n        # Combine similarities with weights\n        combined_similarities = (\n            self.similarity_weights['cosine_sbert'] * similarities['cosine_sbert'] +\n            self.similarity_weights['euclidean_sbert'] * similarities['euclidean_sbert'] +\n            self.similarity_weights['manhattan_sbert'] * similarities['manhattan_sbert'] +\n            self.similarity_weights['cosine_tfidf'] * similarities['cosine_tfidf'] +\n            self.similarity_weights['euclidean_tfidf'] * similarities['euclidean_tfidf']\n        )\n        \n        # Get top-k results\n        top_indices = np.argsort(combined_similarities)[::-1][:top_k]\n        \n        results = []\n        for idx in top_indices:\n            individual_scores = {name: sim[idx] for name, sim in similarities.items()}\n            results.append((idx, combined_similarities[idx], individual_scores))\n        \n        return results\n\n# Example usage:\nif __name__ == \"__main__\":\n    # Custom weights example\n    weights = {\n        'cosine_sbert': 0.4,\n        'euclidean_sbert': 0.3,\n        'manhattan_sbert': 0.3,\n        'cosine_tfidf': 0.4,\n        'euclidean_tfidf': 0.6\n    }\n    \n    # Load your embeddings here\n    # sbert = np.load('path_to_sbert_embeddings.npy')\n    # tfidf_sparse = csr_matrix(np.load('path_to_tfidf_embeddings.npy'))\n    \n    retriever = SimilarityRetriever(sbert, tfidf_sparse, similarity_weights=weights)\n    \n    query_idx = 0\n    similar_trials = retriever.find_similar_trials(query_idx, top_k=10)\n    \n    print(f\"\\nMost similar trials to trial {query_idx}:\")\n    for idx, combined_score, individual_scores in similar_trials:\n        print(f\"\\nTrial {idx}\")\n        print(f\"Combined similarity: {combined_score:.4f}\")\n        for metric, score in individual_scores.items():\n            print(f\"{metric}: {score:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Now for the model development phase we are going to follow the following guidelines:\nPhase 1: Data Preparation and Label Generation\n\n    Create Training Pairs\n\n    Define Similarity Labels\n\n    Option A: Use existing embeddings to create silver-standard labels\n    Option B: Use domain-specific rules (same disease area, intervention)\n    Option C: Get expert annotations for a subset\nPhase 2: Model Architecture Design\n\n    Siamese Network Base\n    Feature Integration\nPhase 3: Training Pipeline Setup\n\n    Data Loading\n    Training Loop\nPhase 4: Model Evaluation\n\n    Metrics Implementation\n","metadata":{}},{"cell_type":"markdown","source":"#### Starting with phase 1","metadata":{}},{"cell_type":"code","source":"# Installing some dependecies for better performance\n! pip install psutil tqdm joblib torch pandas numpy scipy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T06:00:39.066682Z","iopub.execute_input":"2025-01-01T06:00:39.067076Z","iopub.status.idle":"2025-01-01T06:00:43.532131Z","shell.execute_reply.started":"2025-01-01T06:00:39.067043Z","shell.execute_reply":"2025-01-01T06:00:43.531321Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.5)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (1.13.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from tqdm.notebook import tqdm\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom joblib import Parallel, delayed\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nimport torch.cuda.amp as amp\nimport gc\nimport time\nimport psutil\nfrom contextlib import contextmanager\nfrom typing import List, Tuple, Dict\nfrom scipy.sparse import csr_matrix\nimport traceback\n\n@contextmanager\ndef timer(name: str):\n    \"\"\"Simple timing context manager\"\"\"\n    start = time.time()\n    yield\n    print(f\"{name} took {time.time() - start:.2f} seconds\")\n    \ndef process_tfidf_chunk(start_idx: int, end_idx: int, batch_start: int, batch_end: int, tfidf_matrix: csr_matrix) -> np.ndarray:\n    \"\"\"\n    Process a chunk of TF-IDF matrix to compute similarities.\n    \n    Args:\n        start_idx: Start index of the chunk\n        end_idx: End index of the chunk\n        batch_start: Start index of the batch\n        batch_end: End index of the batch\n        tfidf_matrix: The TF-IDF sparse matrix\n        \n    Returns:\n        np.ndarray: Cosine similarities for the chunk\n    \"\"\"\n    return cosine_similarity(\n        tfidf_matrix[batch_start:batch_end],\n        tfidf_matrix[start_idx:end_idx]\n    )\n\ndef compute_tfidf_pair(tfidf_matrix: csr_matrix, x: int, y: int) -> float:\n    \"\"\"\n    Standalone function to avoid lambda references for joblib.\n    Computes the TF-IDF cosine similarity between two rows in the TF-IDF matrix.\n    \"\"\"\n    return cosine_similarity(\n        tfidf_matrix[x].reshape(1, -1),\n        tfidf_matrix[y].reshape(1, -1)\n    )[0][0]\n\nclass DataPairGenerator:\n    def __init__(self, \n                 df: pd.DataFrame,\n                 sbert_embeddings: np.ndarray,\n                 tfidf_embeddings: csr_matrix,\n                 sbert_threshold: float = 0.8,\n                 tfidf_threshold: float = 0.5,\n                 pos_neg_ratio: float = 1.0,\n                 batch_size: int = 512):\n        \"\"\"\n        Initialize the pair generator with simplified GPU references\n        to avoid unpicklable objects when using joblib.\n        \"\"\"\n        print(\"Initializing DataPairGenerator...\")\n        self.df = df\n        print(f\"Loaded DataFrame with {len(df)} rows.\")\n        self.tfidf_embeddings = tfidf_embeddings\n        print(f\"Loaded Tf-IDF embeddings with shape {tfidf_embeddings.shape}.\")\n        self.sbert_threshold = sbert_threshold\n        self.tfidf_threshold = tfidf_threshold\n        self.pos_neg_ratio = pos_neg_ratio\n        self.batch_size = batch_size\n        \n        # Convert SBERT embeddings to torch tensor (float16 for memory efficiency)\n        print(\"Converting SBERT embeddings to PyTorch tensor...\")\n        self.sbert_embeddings = torch.from_numpy(np.array(sbert_embeddings, dtype=np.float16))\n        \n        # Create index mapping for NCT IDs\n        self.nct_to_idx = {nct: idx for idx, nct in enumerate(df['nct_id'])}\n        \n        # Check GPU availability\n        if torch.cuda.is_available():\n            print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n            self.sbert_embeddings = self.sbert_embeddings.cuda()\n        else:\n            print(\"No GPU available. Using CPU only.\")\n        \n        print(\"Initialization complete.\")\n\n    def compute_batch_similarities(self, batch_start: int, batch_end: int) -> Tuple[np.ndarray, np.ndarray]:\n        \"\"\"\n        Compute SBERT and TF-IDF similarities for a batch.\n        \"\"\"\n        chunk_size = 2000\n        if torch.cuda.is_available():\n            with torch.cuda.device(0):\n                batch_sbert = self.sbert_embeddings[batch_start:batch_end].cuda().float()\n                sbert_sims_list = []\n                \n                # Add progress bar for SBERT similarity computation\n                chunks = range(0, len(self.sbert_embeddings), chunk_size)\n                with tqdm(total=len(chunks), desc=\"Computing SBERT similarities\", leave=False) as pbar:\n                    with torch.autocast(\"cuda\", dtype=torch.float16):\n                        for i in chunks:\n                            chunk_end = min(i + chunk_size, len(self.sbert_embeddings))\n                            chunk_sbert = self.sbert_embeddings[i:chunk_end].cuda().float()\n                            chunk_sims = F.cosine_similarity(\n                                batch_sbert.unsqueeze(1),\n                                chunk_sbert.unsqueeze(0),\n                                dim=2\n                            )\n                            sbert_sims_list.append(chunk_sims.cpu().numpy())\n                            del chunk_sbert\n                            pbar.update(1)\n                            \n                sbert_sims = np.concatenate(sbert_sims_list, axis=1)\n                del batch_sbert, sbert_sims_list\n                torch.cuda.empty_cache()\n        else:\n            batch_sbert = self.sbert_embeddings[batch_start:batch_end].float()\n            sbert_sims_list = []\n            chunks = range(0, len(self.sbert_embeddings), chunk_size)\n            with tqdm(total=len(chunks), desc=\"Computing SBERT similarities\", leave=False) as pbar:\n                for i in chunks:\n                    chunk_end = min(i + chunk_size, len(self.sbert_embeddings))\n                    chunk_sbert = self.sbert_embeddings[i:chunk_end].float()\n                    chunk_sims = F.cosine_similarity(\n                        batch_sbert.unsqueeze(1),\n                        chunk_sbert.unsqueeze(0),\n                        dim=2\n                    )\n                    sbert_sims_list.append(chunk_sims.numpy())\n                    pbar.update(1)\n            sbert_sims = np.concatenate(sbert_sims_list, axis=1)\n        \n        # Parallelize TF-IDF computation\n        n_jobs = min(psutil.cpu_count() - 1, 8)\n        chunk_size = min(5000, self.tfidf_embeddings.shape[0] // n_jobs)\n        chunks = range(0, self.tfidf_embeddings.shape[0], chunk_size)\n        \n        tfidf_chunks = Parallel(n_jobs=n_jobs, prefer='threads')(\n            delayed(process_tfidf_chunk)(i, min(i + chunk_size, self.tfidf_embeddings.shape[0]), batch_start, batch_end, self.tfidf_embeddings)\n            for i in tqdm(chunks, desc=\"TF-IDF chunks\", leave=False)\n        )\n        tfidf_sims = np.hstack(tfidf_chunks)\n        \n        return sbert_sims, tfidf_sims\n\n    def generate_positive_pairs(self, sample_size: int = None) -> List[Tuple[str, str]]:\n        positive_pairs = []\n        num_trials = len(self.df)\n        \n        print(\"\\nGenerating positive pairs...\")\n        with tqdm(total=num_trials, desc=\"Processing batches\") as pbar:\n            for i in range(0, num_trials, self.batch_size):\n                batch_end = min(i + self.batch_size, num_trials)\n                sbert_sims, tfidf_sims = self.compute_batch_similarities(i, batch_end)\n                \n                for idx in range(batch_end - i):\n                    local_pairs = []\n                    global_idx = i + idx\n                    nct_id = self.df.iloc[global_idx]['nct_id']\n\n                    similar_mask = (sbert_sims[idx] > self.sbert_threshold) & \\\n                                   (tfidf_sims[idx] > self.tfidf_threshold)\n                    similar_indices = np.where(similar_mask)[0]\n                    similar_indices = similar_indices[similar_indices != global_idx]\n\n                    similar_ncts = self.df.iloc[similar_indices]['nct_id'].values\n                    local_pairs.extend(list(zip([nct_id] * len(similar_ncts), similar_ncts)))\n                    positive_pairs.extend(local_pairs)\n\n                pbar.update(batch_end - i)\n                del sbert_sims, tfidf_sims\n                gc.collect()\n\n        if sample_size:\n            positive_pairs = np.random.choice(\n                positive_pairs,\n                size=min(sample_size, len(positive_pairs)),\n                replace=False\n            ).tolist()\n        \n        print(f\"Generated {len(positive_pairs)} positive pairs\")\n        return positive_pairs\n\n    def generate_negative_pairs(self, num_pairs: int) -> List[Tuple[str, str]]:\n        \"\"\"\n        Generate negative pairs with handling for small datasets.\n        \"\"\"\n        negative_pairs = []\n        num_trials = len(self.df)\n        \n        # Calculate maximum possible unique pairs\n        max_possible_pairs = (num_trials * (num_trials - 1)) // 2\n        \n        # Adjust batch size based on dataset size\n        batch_size = min(1000, max(10, num_trials // 2))\n        \n        # Adjust number of pairs if necessary\n        num_pairs = min(num_pairs, max_possible_pairs)\n        print(f\"Aiming to generate {num_pairs} negative pairs (maximum possible: {max_possible_pairs})\")\n        \n        print(\"\\nGenerating negative pairs...\")\n        with tqdm(total=num_pairs, desc=\"Finding negative pairs\") as pbar:\n            while len(negative_pairs) < num_pairs:\n                # Calculate how many more pairs we need\n                pairs_needed = num_pairs - len(negative_pairs)\n                \n                # Adjust batch size if we're near the end\n                current_batch_size = min(batch_size, pairs_needed * 2)\n                \n                # Generate random indices with replacement for small datasets\n                idx1 = np.random.randint(0, num_trials, size=current_batch_size)\n                idx2 = np.random.randint(0, num_trials, size=current_batch_size)\n                \n                # Remove self-pairs\n                valid_mask = idx1 != idx2\n                idx1 = idx1[valid_mask]\n                idx2 = idx2[valid_mask]\n                \n                if len(idx1) == 0:\n                    continue\n                \n                # Reshape for similarity computation\n                indices = np.column_stack((idx1, idx2))\n                \n                if torch.cuda.is_available():\n                    with torch.cuda.device(0):\n                        sbert_sims = F.cosine_similarity(\n                            self.sbert_embeddings[indices[:, 0]].cuda().float(),\n                            self.sbert_embeddings[indices[:, 1]].cuda().float()\n                        ).cpu().numpy()\n                else:\n                    sbert_sims = F.cosine_similarity(\n                        self.sbert_embeddings[indices[:, 0]].float(),\n                        self.sbert_embeddings[indices[:, 1]].float()\n                    ).numpy()\n    \n                tfidf_sims = Parallel(n_jobs=min(psutil.cpu_count() - 1, 8), prefer='threads')(\n                    delayed(compute_tfidf_pair)(self.tfidf_embeddings, idx1, idx2)\n                    for idx1, idx2 in indices\n                )\n    \n                # Find valid negative pairs\n                valid_mask = (sbert_sims < self.sbert_threshold / 2) & \\\n                            (np.array(tfidf_sims) < self.tfidf_threshold / 2)\n                \n                valid_indices = indices[valid_mask]\n                new_pairs = [\n                    (self.df.iloc[idx1]['nct_id'], self.df.iloc[idx2]['nct_id'])\n                    for idx1, idx2 in valid_indices\n                ]\n                \n                # Convert to set for uniqueness check\n                existing_pairs = set((p1, p2) for p1, p2 in negative_pairs)\n                new_unique_pairs = [\n                    pair for pair in new_pairs \n                    if pair not in existing_pairs and (pair[1], pair[0]) not in existing_pairs\n                ]\n                \n                # Add new unique pairs\n                negative_pairs.extend(new_unique_pairs[:num_pairs - len(negative_pairs)])\n                pbar.update(min(len(new_unique_pairs), num_pairs - pbar.n))\n                \n                # Clear memory\n                del sbert_sims, tfidf_sims\n                gc.collect()\n                \n                # Break if we can't find any more valid pairs\n                if len(new_unique_pairs) == 0 and len(negative_pairs) < num_pairs:\n                    print(f\"\\nWarning: Could only generate {len(negative_pairs)} negative pairs\")\n                    break\n    \n        return negative_pairs[:num_pairs]\n\n    def create_training_pairs(self, \n                              total_pairs: int = 100000,\n                              validation_split: float = 0.2) -> Dict[str, pd.DataFrame]:\n        print(\"\\nCreating training pairs...\")\n        num_pos = min(int(total_pairs / (1 + self.pos_neg_ratio)), len(self.df) * (len(self.df) - 1) // 4)\n        \n        print(f\"Generating positive pairs...\")\n        pos_pairs = self.generate_positive_pairs()\n        pos_pairs = pos_pairs[:num_pos]\n        actual_pos = len(pos_pairs)\n        \n        num_neg = int(actual_pos * self.pos_neg_ratio)\n        print(f\"Generating {num_neg} negative pairs...\")\n        neg_pairs = self.generate_negative_pairs(num_neg)\n        \n        print(\"\\nCreating final datasets...\")\n        all_pairs = [(p1, p2, 1) for p1, p2 in pos_pairs] + \\\n                    [(p1, p2, 0) for p1, p2 in neg_pairs]\n        np.random.shuffle(all_pairs)\n        \n        pair_df = pd.DataFrame(all_pairs, columns=['nct_id_1', 'nct_id_2', 'label'])\n        \n        print(\"Merging with original dataframe...\")\n        for suffix in ['1', '2']:\n            pair_df = pair_df.merge(\n                self.df.add_suffix(f'_{suffix}'),\n                left_on=f'nct_id_{suffix}',\n                right_on=f'nct_id_{suffix}',\n                how='left'\n            )\n        \n        # Split into train and validation\n        mask = np.random.rand(len(pair_df)) > validation_split\n        train_df = pair_df[mask]\n        val_df = pair_df[~mask]\n        \n        print(f\"Created {len(train_df)} training pairs and {len(val_df)} validation pairs\")\n        return {\n            'train': train_df,\n            'validation': val_df\n        }\n\ndef load_embeddings(sbert_path: str, tfidf_path: str) -> Tuple[np.ndarray, csr_matrix]:\n    \"\"\"Load and verify embeddings from files.\"\"\"\n    try:\n        print(f\"Loading SBERT embeddings from {sbert_path}\")\n        sbert = np.load(sbert_path)\n        print(f\"SBERT embeddings shape: {sbert.shape}\")\n        \n        print(f\"Loading TF-IDF embeddings from {tfidf_path}\")\n        tfidf_sparse = np.load(tfidf_path, allow_pickle=True)\n        tfidf = csr_matrix(\n            (tfidf_sparse['data'], tfidf_sparse['indices'], tfidf_sparse['indptr']),\n            shape=tuple(tfidf_sparse['shape'])\n        )\n        print(f\"TF-IDF embeddings shape: {tfidf.shape}\")\n        \n        if not np.issubdtype(sbert.dtype, np.number):\n            raise ValueError(f\"SBERT embeddings contain non-numeric data: {sbert.dtype}\")\n        if not np.issubdtype(tfidf.dtype, np.number):\n            raise ValueError(f\"TF-IDF embeddings contain non-numeric data: {tfidf.dtype}\")\n        \n        if np.isnan(sbert).any() or np.isinf(sbert).any():\n            raise ValueError(\"SBERT embeddings contain NaN or infinite values\")\n        if np.isnan(tfidf.data).any() or np.isinf(tfidf.data).any():\n            raise ValueError(\"TF-IDF embeddings contain NaN or infinite values\")\n        \n        return sbert, tfidf\n    except Exception as e:\n        print(f\"Error loading embeddings: {str(e)}\")\n        raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T06:00:49.123997Z","iopub.execute_input":"2025-01-01T06:00:49.124285Z","iopub.status.idle":"2025-01-01T06:00:53.006068Z","shell.execute_reply.started":"2025-01-01T06:00:49.124264Z","shell.execute_reply":"2025-01-01T06:00:53.005162Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"sbert_path = '/kaggle/input/nest-ps-1-sbert-embeddings/sbert_embeddings_final_20241228-170631.npy'\ntfidf_path = '/kaggle/input/nest-ps-1-tfidf-embeddings/tfidf_vectors_final_20241228-170631.npz'\n\nsbert, tfidf_sparse = load_embeddings(sbert_path, tfidf_path)\n\ndf = pd.read_csv('/kaggle/input/nest-ps-1-data-cleaning-done/clinical_trials_processed_with_missing_handled.csv')\nprint(f\"DataFrame shape: {df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T06:01:00.065083Z","iopub.execute_input":"2025-01-01T06:01:00.065526Z","iopub.status.idle":"2025-01-01T06:01:32.025307Z","shell.execute_reply.started":"2025-01-01T06:01:00.065502Z","shell.execute_reply":"2025-01-01T06:01:32.024396Z"}},"outputs":[{"name":"stdout","text":"Loading SBERT embeddings from /kaggle/input/nest-ps-1-sbert-embeddings/sbert_embeddings_final_20241228-170631.npy\nSBERT embeddings shape: (393934, 768)\nLoading TF-IDF embeddings from /kaggle/input/nest-ps-1-tfidf-embeddings/tfidf_vectors_final_20241228-170631.npz\nTF-IDF embeddings shape: (393934, 5000)\nDataFrame shape: (393934, 9)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Decrease thresholds or batch sizes for memory constraints\nSBERT_THRESHOLD = 0.75\nTFIDF_THRESHOLD = 0.5\nPOS_NEG_RATIO = 1.0\nTOTAL_PAIRS = 100000\nVALIDATION_SPLIT = 0.2\nBATCH_SIZE = 512  # More conservative batch size\n\ntorch.manual_seed(42)\nnp.random.seed(42)\n\npair_generator = DataPairGenerator(\n    df=df,\n    sbert_embeddings=sbert,\n    tfidf_embeddings=tfidf_sparse,\n    sbert_threshold=SBERT_THRESHOLD,\n    tfidf_threshold=TFIDF_THRESHOLD,\n    pos_neg_ratio=POS_NEG_RATIO,\n    batch_size=BATCH_SIZE\n)\n\nprint(f\"\\nGenerating training pairs (total pairs: {TOTAL_PAIRS})...\")\ntry:\n    with timer(\"Total dataset creation\"):  # Changed from test_generator.timer\n        pair_datasets = pair_generator.create_training_pairs(\n            total_pairs=TOTAL_PAIRS,\n            validation_split=VALIDATION_SPLIT\n        )\n        \n    timestamp = pd.Timestamp.now().strftime(\"%Y%m%d-%H%M%S\")\n    print(\"\\nSaving datasets...\")\n    train_path = f'training_pairs_{timestamp}.csv'\n    pair_datasets['train'].to_csv(train_path, index=False)\n    print(f\"Training dataset saved to: {train_path}\")\n    \n    val_path = f'validation_pairs_{timestamp}.csv'\n    pair_datasets['validation'].to_csv(val_path, index=False)\n    print(f\"Validation dataset saved to: {val_path}\")\n\n    print(\"\\nDataset Statistics:\")\n    print(f\"Training pairs: {len(pair_datasets['train']):,}\")\n    print(f\"Validation pairs: {len(pair_datasets['validation']):,}\")\n    \n    train_pos = (pair_datasets['train']['label'] == 1).sum()\n    train_neg = (pair_datasets['train']['label'] == 0).sum()\n    val_pos = (pair_datasets['validation']['label'] == 1).sum()\n    val_neg = (pair_datasets['validation']['label'] == 0).sum()\n    \n    print(\"\\nClass Distribution:\")\n    print(f\"Training - Positive: {train_pos:,} ({train_pos/len(pair_datasets['train'])*100:.1f}%)\")\n    print(f\"Training - Negative: {train_neg:,} ({train_neg/len(pair_datasets['train'])*100:.1f}%)\")\n    print(f\"Validation - Positive: {val_pos:,} ({val_pos/len(pair_datasets['validation'])*100:.1f}%)\")\n    print(f\"Validation - Negative: {val_neg:,} ({val_neg/len(pair_datasets['validation'])*100:.1f}%)\")\n\nexcept Exception as e:\n    print(f\"\\nError during pair generation: {str(e)}\")\n    raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T06:01:40.696946Z","iopub.execute_input":"2025-01-01T06:01:40.697292Z","execution_failed":"2025-01-01T10:08:44.097Z"},"_kg_hide-output":false,"_kg_hide-input":true,"scrolled":true},"outputs":[{"name":"stdout","text":"Initializing DataPairGenerator...\nLoaded DataFrame with 393934 rows.\nLoaded Tf-IDF embeddings with shape (393934, 5000).\nConverting SBERT embeddings to PyTorch tensor...\nUsing GPU: Tesla P100-PCIE-16GB\nInitialization complete.\n\nGenerating training pairs (total pairs: 100000)...\n\nCreating training pairs...\nGenerating positive pairs...\n\nGenerating positive pairs...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing batches:   0%|          | 0/393934 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9280b7a04cb2439fa6929058029a0043"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05182b588c904bc398644775cb9f83ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b6a8614d2e5489099798332beb0a3da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/79 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/197 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f14a853a71714459817c664d863a363f"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"# Example: select the first 1000 rows from the DataFrame\ndf_subset = df[:10000]\n\n# For SBERT embeddings, slice to match the first 1000 rows\nsbert_subset = sbert[:10000]\n\n# For TF-IDF (csr_matrix), slice the rows to match the first 1000 as well\ntfidf_subset = tfidf_sparse[:10000, :]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:31.817596Z","iopub.execute_input":"2025-01-01T05:20:31.817938Z","iopub.status.idle":"2025-01-01T05:20:31.830265Z","shell.execute_reply.started":"2025-01-01T05:20:31.817910Z","shell.execute_reply":"2025-01-01T05:20:31.829460Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Decrease thresholds or batch sizes for memory constraints\nSBERT_THRESHOLD = 0.75\nTFIDF_THRESHOLD = 0.5\nPOS_NEG_RATIO = 1.0\nTOTAL_PAIRS = 100\nVALIDATION_SPLIT = 0.2\nBATCH_SIZE = 256  # More conservative batch size\n\ntorch.manual_seed(42)\nnp.random.seed(42)\n\n\n\npair_generator = DataPairGenerator(\n    df=df_subset,\n    sbert_embeddings=sbert_subset,\n    tfidf_embeddings=tfidf_subset,\n    sbert_threshold=SBERT_THRESHOLD,\n    tfidf_threshold=TFIDF_THRESHOLD,\n    pos_neg_ratio=POS_NEG_RATIO,\n    batch_size=BATCH_SIZE\n)\n\nprint(f\"\\nGenerating training pairs (total pairs: {TOTAL_PAIRS})...\")\ntry:\n    with timer(\"Total dataset creation\"):  # Changed from test_generator.timer\n        pair_datasets = pair_generator.create_training_pairs(\n            total_pairs=TOTAL_PAIRS,\n            validation_split=VALIDATION_SPLIT\n        )\n        \n    timestamp = pd.Timestamp.now().strftime(\"%Y%m%d-%H%M%S\")\n    print(\"\\nSaving datasets...\")\n    train_path = f'training_pairs_{timestamp}.csv'\n    pair_datasets['train'].to_csv(train_path, index=False)\n    print(f\"Training dataset saved to: {train_path}\")\n    \n    val_path = f'validation_pairs_{timestamp}.csv'\n    pair_datasets['validation'].to_csv(val_path, index=False)\n    print(f\"Validation dataset saved to: {val_path}\")\n\n    print(\"\\nDataset Statistics:\")\n    print(f\"Training pairs: {len(pair_datasets['train']):,}\")\n    print(f\"Validation pairs: {len(pair_datasets['validation']):,}\")\n    \n    train_pos = (pair_datasets['train']['label'] == 1).sum()\n    train_neg = (pair_datasets['train']['label'] == 0).sum()\n    val_pos = (pair_datasets['validation']['label'] == 1).sum()\n    val_neg = (pair_datasets['validation']['label'] == 0).sum()\n    \n    print(\"\\nClass Distribution:\")\n    print(f\"Training - Positive: {train_pos:,} ({train_pos/len(pair_datasets['train'])*100:.1f}%)\")\n    print(f\"Training - Negative: {train_neg:,} ({train_neg/len(pair_datasets['train'])*100:.1f}%)\")\n    print(f\"Validation - Positive: {val_pos:,} ({val_pos/len(pair_datasets['validation'])*100:.1f}%)\")\n    print(f\"Validation - Negative: {val_neg:,} ({val_neg/len(pair_datasets['validation'])*100:.1f}%)\")\n\nexcept Exception as e:\n    print(f\"\\nError during pair generation: {str(e)}\")\n    raise","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:24:48.647236Z","iopub.execute_input":"2025-01-01T05:24:48.647594Z","iopub.status.idle":"2025-01-01T05:25:04.605918Z","shell.execute_reply.started":"2025-01-01T05:24:48.647565Z","shell.execute_reply":"2025-01-01T05:25:04.605152Z"}},"outputs":[{"name":"stdout","text":"Initializing DataPairGenerator...\nLoaded DataFrame with 10000 rows.\nLoaded Tf-IDF embeddings with shape (10000, 5000).\nConverting SBERT embeddings to PyTorch tensor...\nUsing GPU: Tesla P100-PCIE-16GB\nInitialization complete.\n\nGenerating training pairs (total pairs: 100)...\n\nCreating training pairs...\nGenerating positive pairs...\n\nGenerating positive pairs...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Processing batches:   0%|          | 0/10000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e5e36faf28c463daf5ecdcaa3cec234"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Computing SBERT similarities:   0%|          | 0/5 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"TF-IDF chunks:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Generated 13980 positive pairs\nGenerating 50 negative pairs...\nAiming to generate 50 negative pairs (maximum possible: 49995000)\n\nGenerating negative pairs...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Finding negative pairs:   0%|          | 0/50 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74fcec72f5ed46938964831f84391cf2"}},"metadata":{}},{"name":"stdout","text":"\nWarning: Could only generate 0 negative pairs\n\nCreating final datasets...\nMerging with original dataframe...\nCreated 172 training pairs and 40 validation pairs\nTotal dataset creation took 15.83 seconds\n\nSaving datasets...\nTraining dataset saved to: training_pairs_20250101-052504.csv\nValidation dataset saved to: validation_pairs_20250101-052504.csv\n\nDataset Statistics:\nTraining pairs: 172\nValidation pairs: 40\n\nClass Distribution:\nTraining - Positive: 172 (100.0%)\nTraining - Negative: 0 (0.0%)\nValidation - Positive: 40 (100.0%)\nValidation - Negative: 0 (0.0%)\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv('/kaggle/input/train-val-pair-for-siamese-network/training_pairs_20250101-093156.csv')\nval_df = pd.read_csv('/kaggle/input/train-val-pair-for-siamese-network/training_pairs_20250101-093156.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T10:46:59.691258Z","iopub.execute_input":"2025-01-01T10:46:59.691629Z","iopub.status.idle":"2025-01-01T10:47:44.249307Z","shell.execute_reply.started":"2025-01-01T10:46:59.691568Z","shell.execute_reply":"2025-01-01T10:47:44.248635Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"train_df.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T10:53:15.318029Z","iopub.execute_input":"2025-01-01T10:53:15.318314Z","iopub.status.idle":"2025-01-01T10:53:15.333414Z","shell.execute_reply.started":"2025-01-01T10:53:15.318293Z","shell.execute_reply":"2025-01-01T10:53:15.332584Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"           nct_id_1     nct_id_2  label  \\\n198496  NCT04465266  NCT04465266      1   \n198497  NCT04465266  NCT04465266      1   \n198498  NCT04465266  NCT04465266      1   \n198499  NCT04465266  NCT04465266      1   \n198500  NCT04465266  NCT04465266      1   \n\n                                    Study Title_Cleaned_1  \\\n198496  a phase 1 pk study of tolperisone in healthy s...   \n198497  a phase 1 pk study of tolperisone in healthy s...   \n198498  a phase 1 pk study of tolperisone in healthy s...   \n198499  a phase 1 pk study of tolperisone in healthy s...   \n198500  a phase 1 pk study of tolperisone in healthy s...   \n\n                       Primary Outcome Measures_Cleaned_1  \\\n198496  cmax maximum plasma concentration of tolperiso...   \n198497  cmax maximum plasma concentration of tolperiso...   \n198498  cmax maximum plasma concentration of tolperiso...   \n198499  cmax maximum plasma concentration of tolperiso...   \n198500  cmax maximum plasma concentration of tolperiso...   \n\n       Secondary Outcome Measures_Cleaned_1  \\\n198496       no secondary outcomes provided   \n198497       no secondary outcomes provided   \n198498       no secondary outcomes provided   \n198499       no secondary outcomes provided   \n198500       no secondary outcomes provided   \n\n                                       criteria_Cleaned_1  \\\n198496  inclusion criteria generally healthy subjects ...   \n198497  inclusion criteria generally healthy subjects ...   \n198498  inclusion criteria generally healthy subjects ...   \n198499  inclusion criteria generally healthy subjects ...   \n198500  inclusion criteria generally healthy subjects ...   \n\n        Secondary_Outcome_Missing_1  Primary_Outcome_Missing_1  \\\n198496                            1                          0   \n198497                            1                          0   \n198498                            1                          0   \n198499                            1                          0   \n198500                            1                          0   \n\n        Criteria_Missing_1  completeness_score_1  \\\n198496                   0                   0.8   \n198497                   0                   0.8   \n198498                   0                   0.8   \n198499                   0                   0.8   \n198500                   0                   0.8   \n\n                                    Study Title_Cleaned_2  \\\n198496  a phase 1 pk study of tolperisone in healthy s...   \n198497  a phase 1 pk study of tolperisone in healthy s...   \n198498  a phase 1 pk study of tolperisone in healthy s...   \n198499  a phase 1 pk study of tolperisone in healthy s...   \n198500  a phase 1 pk study of tolperisone in healthy s...   \n\n                       Primary Outcome Measures_Cleaned_2  \\\n198496  cmax maximum plasma concentration of tolperiso...   \n198497  cmax maximum plasma concentration of tolperiso...   \n198498  cmax maximum plasma concentration of tolperiso...   \n198499  cmax maximum plasma concentration of tolperiso...   \n198500  cmax maximum plasma concentration of tolperiso...   \n\n       Secondary Outcome Measures_Cleaned_2  \\\n198496       no secondary outcomes provided   \n198497       no secondary outcomes provided   \n198498       no secondary outcomes provided   \n198499       no secondary outcomes provided   \n198500       no secondary outcomes provided   \n\n                                       criteria_Cleaned_2  \\\n198496  inclusion criteria generally healthy subjects ...   \n198497  inclusion criteria generally healthy subjects ...   \n198498  inclusion criteria generally healthy subjects ...   \n198499  inclusion criteria generally healthy subjects ...   \n198500  inclusion criteria generally healthy subjects ...   \n\n        Secondary_Outcome_Missing_2  Primary_Outcome_Missing_2  \\\n198496                            1                          0   \n198497                            1                          0   \n198498                            1                          0   \n198499                            1                          0   \n198500                            1                          0   \n\n        Criteria_Missing_2  completeness_score_2  \n198496                   0                   0.8  \n198497                   0                   0.8  \n198498                   0                   0.8  \n198499                   0                   0.8  \n198500                   0                   0.8  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nct_id_1</th>\n      <th>nct_id_2</th>\n      <th>label</th>\n      <th>Study Title_Cleaned_1</th>\n      <th>Primary Outcome Measures_Cleaned_1</th>\n      <th>Secondary Outcome Measures_Cleaned_1</th>\n      <th>criteria_Cleaned_1</th>\n      <th>Secondary_Outcome_Missing_1</th>\n      <th>Primary_Outcome_Missing_1</th>\n      <th>Criteria_Missing_1</th>\n      <th>completeness_score_1</th>\n      <th>Study Title_Cleaned_2</th>\n      <th>Primary Outcome Measures_Cleaned_2</th>\n      <th>Secondary Outcome Measures_Cleaned_2</th>\n      <th>criteria_Cleaned_2</th>\n      <th>Secondary_Outcome_Missing_2</th>\n      <th>Primary_Outcome_Missing_2</th>\n      <th>Criteria_Missing_2</th>\n      <th>completeness_score_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>198496</th>\n      <td>NCT04465266</td>\n      <td>NCT04465266</td>\n      <td>1</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>198497</th>\n      <td>NCT04465266</td>\n      <td>NCT04465266</td>\n      <td>1</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>198498</th>\n      <td>NCT04465266</td>\n      <td>NCT04465266</td>\n      <td>1</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>198499</th>\n      <td>NCT04465266</td>\n      <td>NCT04465266</td>\n      <td>1</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>198500</th>\n      <td>NCT04465266</td>\n      <td>NCT04465266</td>\n      <td>1</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"train_df['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T10:53:35.795064Z","iopub.execute_input":"2025-01-01T10:53:35.795416Z","iopub.status.idle":"2025-01-01T10:53:35.802741Z","shell.execute_reply.started":"2025-01-01T10:53:35.795385Z","shell.execute_reply":"2025-01-01T10:53:35.801912Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"label\n1    198501\nName: count, dtype: int64"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"### Writing the model architecture","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom transformers import AutoModel, AutoTokenizer\n\nclass SiameseNetwork(nn.Module):\n    def __init__(self, model_name='allenai/scibert_scivocab_uncased', hidden_size=768):\n        super(SiameseNetwork, self).__init__()\n        \n        # Initialize BERT encoder\n        self.encoder = AutoModel.from_pretrained(model_name)\n        \n        # Projection layers\n        self.projection = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.LayerNorm(hidden_size),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(hidden_size, hidden_size)\n        )\n        \n    def forward_once(self, input_ids, attention_mask):\n        # Get BERT outputs\n        outputs = self.encoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            return_dict=True\n        )\n        \n        # Use CLS token representation\n        pooled = outputs.last_hidden_state[:, 0]\n        \n        # Project to final embedding\n        projected = self.projection(pooled)\n        return projected\n        \n    def forward(self, input_ids1, attention_mask1, input_ids2, attention_mask2):\n        # Get embeddings for both trials\n        emb1 = self.forward_once(input_ids1, attention_mask1)\n        emb2 = self.forward_once(input_ids2, attention_mask2)\n        return emb1, emb2\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class HybridEncoder(nn.Module):\n    def __init__(self, \n                 model_name='allenai/scibert_scivocab_uncased', \n                 text_dim=768,\n                 tfidf_dim=5000,\n                 numeric_dim=3):  # completeness_score + 2 missing flags\n        super(HybridEncoder, self).__init__()\n        \n        # Text encoder (BERT)\n        self.text_encoder = AutoModel.from_pretrained(model_name)\n        \n        # TF-IDF encoder\n        self.tfidf_encoder = nn.Sequential(\n            nn.Linear(tfidf_dim, 256),\n            nn.LayerNorm(256),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(256, 128)\n        )\n        \n        # Numeric features encoder\n        self.numeric_encoder = nn.Sequential(\n            nn.Linear(numeric_dim, 32),\n            nn.LayerNorm(32),\n            nn.ReLU(),\n            nn.Linear(32, 16)\n        )\n        \n        # Fusion layer\n        combined_dim = text_dim + 128 + 16  # BERT + TF-IDF + numeric\n        self.fusion = nn.Sequential(\n            nn.Linear(combined_dim, 512),\n            nn.LayerNorm(512),\n            nn.ReLU(),\n            nn.Dropout(0.1),\n            nn.Linear(512, 256)\n        )\n        \n    def forward_once(self, input_ids, attention_mask, tfidf_vector, numeric_features):\n        # Get BERT embeddings\n        text_outputs = self.text_encoder(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            return_dict=True\n        )\n        text_embeds = text_outputs.last_hidden_state[:, 0]\n        \n        # Encode TF-IDF\n        tfidf_embeds = self.tfidf_encoder(tfidf_vector)\n        \n        # Encode numeric features\n        numeric_embeds = self.numeric_encoder(numeric_features)\n        \n        # Combine all features\n        combined = torch.cat([text_embeds, tfidf_embeds, numeric_embeds], dim=1)\n        \n        # Final fusion\n        fused = self.fusion(combined)\n        return fused\n        \n    def forward(self, batch):\n        # Process first trial\n        emb1 = self.forward_once(\n            batch['input_ids1'],\n            batch['attention_mask1'],\n            batch['tfidf1'],\n            batch['numeric1']\n        )\n        \n        # Process second trial\n        emb2 = self.forward_once(\n            batch['input_ids2'],\n            batch['attention_mask2'],\n            batch['tfidf2'],\n            batch['numeric2']\n        )\n        \n        return emb1, emb2\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ContrastiveLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n        \n    def forward(self, emb1, emb2, label):\n        # Calculate euclidean distance\n        distance = F.pairwise_distance(emb1, emb2)\n        \n        # Contrastive loss\n        loss = torch.mean((1 - label) * torch.pow(distance, 2) + \n                         label * torch.pow(torch.clamp(self.margin - distance, min=0.0), 2))\n        return loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TrialDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length=512):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # Tokenize text fields\n        text1 = f\"{row['Study Title_Cleaned_1']} {row['Primary Outcome Measures_Cleaned_1']} {row['criteria_Cleaned_1']}\"\n        text2 = f\"{row['Study Title_Cleaned_2']} {row['Primary Outcome Measures_Cleaned_2']} {row['criteria_Cleaned_2']}\"\n        \n        encoded1 = self.tokenizer(\n            text1,\n            truncation=True,\n            max_length=self.max_length,\n            padding='max_length',\n            return_tensors='pt'\n        )\n        \n        encoded2 = self.tokenizer(\n            text2,\n            truncation=True,\n            max_length=self.max_length,\n            padding='max_length',\n            return_tensors='pt'\n        )\n        \n        # Prepare numeric features\n        numeric1 = torch.tensor([\n            row['completeness_score_1'],\n            row['Secondary_Outcome_Missing_1'],\n            row['Primary_Outcome_Missing_1']\n        ], dtype=torch.float)\n        \n        numeric2 = torch.tensor([\n            row['completeness_score_2'],\n            row['Secondary_Outcome_Missing_2'],\n            row['Primary_Outcome_Missing_2']\n        ], dtype=torch.float)\n        \n        return {\n            'input_ids1': encoded1['input_ids'].squeeze(),\n            'attention_mask1': encoded1['attention_mask'].squeeze(),\n            'input_ids2': encoded2['input_ids'].squeeze(),\n            'attention_mask2': encoded2['attention_mask'].squeeze(),\n            'numeric1': numeric1,\n            'numeric2': numeric2,\n            'label': torch.tensor(row['label'], dtype=torch.float)\n        }\n\ndef train_epoch(model, train_loader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0\n    \n    for batch in tqdm(train_loader, desc='Training'):\n        # Move batch to device\n        batch = {k: v.to(device) for k, v in batch.items()}\n        \n        # Forward pass\n        emb1, emb2 = model(batch)\n        \n        # Compute loss\n        loss = criterion(emb1, emb2, batch['label'])\n        \n        # Backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        total_loss += loss.item()\n    \n    return total_loss / len(train_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv('/kaggle/input/train-val-pair-for-siamese-network/training_pairs_20250101-093156.csv')\nval_df = pd.read_csv('/kaggle/input/train-val-pair-for-siamese-network/validation_pairs_20250101-093156.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T14:56:30.902880Z","iopub.execute_input":"2025-01-01T14:56:30.903248Z","iopub.status.idle":"2025-01-01T14:57:09.566592Z","shell.execute_reply.started":"2025-01-01T14:56:30.903219Z","shell.execute_reply":"2025-01-01T14:57:09.565871Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"val_df['label'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T14:57:21.845539Z","iopub.execute_input":"2025-01-01T14:57:21.845820Z","iopub.status.idle":"2025-01-01T14:57:21.864187Z","shell.execute_reply.started":"2025-01-01T14:57:21.845799Z","shell.execute_reply":"2025-01-01T14:57:21.863315Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"label\n1    49477\nName: count, dtype: int64"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nfrom tqdm.notebook import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T15:05:40.054626Z","iopub.execute_input":"2025-01-01T15:05:40.054906Z","iopub.status.idle":"2025-01-01T15:05:40.182504Z","shell.execute_reply.started":"2025-01-01T15:05:40.054884Z","shell.execute_reply":"2025-01-01T15:05:40.181788Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def generate_negative_pairs(df, num_negative_pairs):\n    \"\"\"Generate negative pairs through random sampling\"\"\"\n    negative_pairs = []\n    unique_trials = df['nct_id_1'].unique()\n    \n    while len(negative_pairs) < num_negative_pairs:\n        # Randomly sample two different trials\n        trial1, trial2 = np.random.choice(unique_trials, size=2, replace=False)\n        \n        # Check if this pair doesn't exist in positive pairs\n        if not df[(df['nct_id_1'] == trial1) & (df['nct_id_2'] == trial2)].shape[0]:\n            negative_pairs.append({\n                'nct_id_1': trial1,\n                'nct_id_2': trial2,\n                'label': 0\n            })\n    \n    return pd.DataFrame(negative_pairs)\n\n# Create balanced dataset\nnum_positive = len(train_df)\nnegative_pairs_df = generate_negative_pairs(train_df, num_positive)\nbalanced_train_df = pd.concat([train_df, negative_pairs_df], ignore_index=True)\nnew_num_positive = len(val_df)\nnew_negative_pairs_df = generate_negative_pairs(val_df, new_num_positive)\nbalanced_val_df = pd.concat([val_df, new_negative_pairs_df], ignore_index=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_negative_pairs(df, num_negative_pairs):\n    \"\"\"Generate negative pairs through random sampling\"\"\"\n    negative_pairs = []\n    unique_trials = df['nct_id_1'].unique()\n    \n    # Initialize tqdm with the total number of negative pairs needed\n    with tqdm(total=num_negative_pairs, desc='Generating negative pairs') as pbar:\n        while len(negative_pairs) < num_negative_pairs:\n            # Randomly sample two different trials\n            trial1, trial2 = np.random.choice(unique_trials, size=2, replace=False)\n            \n            # Check if this pair doesn't exist in positive pairs\n            if not df[(df['nct_id_1'] == trial1) & (df['nct_id_2'] == trial2)].shape[0]:\n                negative_pairs.append({\n                    'nct_id_1': trial1,\n                    'nct_id_2': trial2,\n                    'label': 0\n                })\n                # Update the progress bar\n                pbar.update(1)\n    \n    return pd.DataFrame(negative_pairs)\n\nnum_positive = len(train_df)\nnegative_pairs_df = generate_negative_pairs(train_df, num_positive)\nbalanced_train_df = pd.concat([train_df, negative_pairs_df], ignore_index=True)\nnew_num_positive = len(val_df)\nnew_negative_pairs_df = generate_negative_pairs(val_df, new_num_positive)\nbalanced_val_df = pd.concat([val_df, new_negative_pairs_df], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T15:06:36.861023Z","iopub.execute_input":"2025-01-01T15:06:36.861342Z","iopub.status.idle":"2025-01-01T16:34:45.171055Z","shell.execute_reply.started":"2025-01-01T15:06:36.861318Z","shell.execute_reply":"2025-01-01T16:34:45.170372Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Generating negative pairs:   0%|          | 0/198501 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a49ca9fe0444716aac833954b81b67d"}},"metadata":{}},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=10000.0 (msgs/sec)\nNotebookApp.rate_limit_window=1.0 (secs)\n\nIOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=10000.0 (msgs/sec)\nNotebookApp.rate_limit_window=1.0 (secs)\n\n","name":"stderr","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train_df.tail()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T18:34:53.739605Z","iopub.execute_input":"2025-01-01T18:34:53.739894Z","iopub.status.idle":"2025-01-01T18:34:53.753747Z","shell.execute_reply.started":"2025-01-01T18:34:53.739871Z","shell.execute_reply":"2025-01-01T18:34:53.752878Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"           nct_id_1     nct_id_2  label  \\\n198496  NCT04465266  NCT04465266      1   \n198497  NCT04465266  NCT04465266      1   \n198498  NCT04465266  NCT04465266      1   \n198499  NCT04465266  NCT04465266      1   \n198500  NCT04465266  NCT04465266      1   \n\n                                    Study Title_Cleaned_1  \\\n198496  a phase 1 pk study of tolperisone in healthy s...   \n198497  a phase 1 pk study of tolperisone in healthy s...   \n198498  a phase 1 pk study of tolperisone in healthy s...   \n198499  a phase 1 pk study of tolperisone in healthy s...   \n198500  a phase 1 pk study of tolperisone in healthy s...   \n\n                       Primary Outcome Measures_Cleaned_1  \\\n198496  cmax maximum plasma concentration of tolperiso...   \n198497  cmax maximum plasma concentration of tolperiso...   \n198498  cmax maximum plasma concentration of tolperiso...   \n198499  cmax maximum plasma concentration of tolperiso...   \n198500  cmax maximum plasma concentration of tolperiso...   \n\n       Secondary Outcome Measures_Cleaned_1  \\\n198496       no secondary outcomes provided   \n198497       no secondary outcomes provided   \n198498       no secondary outcomes provided   \n198499       no secondary outcomes provided   \n198500       no secondary outcomes provided   \n\n                                       criteria_Cleaned_1  \\\n198496  inclusion criteria generally healthy subjects ...   \n198497  inclusion criteria generally healthy subjects ...   \n198498  inclusion criteria generally healthy subjects ...   \n198499  inclusion criteria generally healthy subjects ...   \n198500  inclusion criteria generally healthy subjects ...   \n\n        Secondary_Outcome_Missing_1  Primary_Outcome_Missing_1  \\\n198496                            1                          0   \n198497                            1                          0   \n198498                            1                          0   \n198499                            1                          0   \n198500                            1                          0   \n\n        Criteria_Missing_1  completeness_score_1  \\\n198496                   0                   0.8   \n198497                   0                   0.8   \n198498                   0                   0.8   \n198499                   0                   0.8   \n198500                   0                   0.8   \n\n                                    Study Title_Cleaned_2  \\\n198496  a phase 1 pk study of tolperisone in healthy s...   \n198497  a phase 1 pk study of tolperisone in healthy s...   \n198498  a phase 1 pk study of tolperisone in healthy s...   \n198499  a phase 1 pk study of tolperisone in healthy s...   \n198500  a phase 1 pk study of tolperisone in healthy s...   \n\n                       Primary Outcome Measures_Cleaned_2  \\\n198496  cmax maximum plasma concentration of tolperiso...   \n198497  cmax maximum plasma concentration of tolperiso...   \n198498  cmax maximum plasma concentration of tolperiso...   \n198499  cmax maximum plasma concentration of tolperiso...   \n198500  cmax maximum plasma concentration of tolperiso...   \n\n       Secondary Outcome Measures_Cleaned_2  \\\n198496       no secondary outcomes provided   \n198497       no secondary outcomes provided   \n198498       no secondary outcomes provided   \n198499       no secondary outcomes provided   \n198500       no secondary outcomes provided   \n\n                                       criteria_Cleaned_2  \\\n198496  inclusion criteria generally healthy subjects ...   \n198497  inclusion criteria generally healthy subjects ...   \n198498  inclusion criteria generally healthy subjects ...   \n198499  inclusion criteria generally healthy subjects ...   \n198500  inclusion criteria generally healthy subjects ...   \n\n        Secondary_Outcome_Missing_2  Primary_Outcome_Missing_2  \\\n198496                            1                          0   \n198497                            1                          0   \n198498                            1                          0   \n198499                            1                          0   \n198500                            1                          0   \n\n        Criteria_Missing_2  completeness_score_2  \n198496                   0                   0.8  \n198497                   0                   0.8  \n198498                   0                   0.8  \n198499                   0                   0.8  \n198500                   0                   0.8  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>nct_id_1</th>\n      <th>nct_id_2</th>\n      <th>label</th>\n      <th>Study Title_Cleaned_1</th>\n      <th>Primary Outcome Measures_Cleaned_1</th>\n      <th>Secondary Outcome Measures_Cleaned_1</th>\n      <th>criteria_Cleaned_1</th>\n      <th>Secondary_Outcome_Missing_1</th>\n      <th>Primary_Outcome_Missing_1</th>\n      <th>Criteria_Missing_1</th>\n      <th>completeness_score_1</th>\n      <th>Study Title_Cleaned_2</th>\n      <th>Primary Outcome Measures_Cleaned_2</th>\n      <th>Secondary Outcome Measures_Cleaned_2</th>\n      <th>criteria_Cleaned_2</th>\n      <th>Secondary_Outcome_Missing_2</th>\n      <th>Primary_Outcome_Missing_2</th>\n      <th>Criteria_Missing_2</th>\n      <th>completeness_score_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>198496</th>\n      <td>NCT04465266</td>\n      <td>NCT04465266</td>\n      <td>1</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>198497</th>\n      <td>NCT04465266</td>\n      <td>NCT04465266</td>\n      <td>1</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>198498</th>\n      <td>NCT04465266</td>\n      <td>NCT04465266</td>\n      <td>1</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>198499</th>\n      <td>NCT04465266</td>\n      <td>NCT04465266</td>\n      <td>1</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n    </tr>\n    <tr>\n      <th>198500</th>\n      <td>NCT04465266</td>\n      <td>NCT04465266</td>\n      <td>1</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n      <td>a phase 1 pk study of tolperisone in healthy s...</td>\n      <td>cmax maximum plasma concentration of tolperiso...</td>\n      <td>no secondary outcomes provided</td>\n      <td>inclusion criteria generally healthy subjects ...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"class ValidationMetrics:\n    def __init__(self, k_values=[1, 5, 10]):\n        self.k_values = k_values\n    \n    def precision_at_k(self, similarities, labels, k):\n        \"\"\"Calculate Precision@K\"\"\"\n        _, top_k_indices = similarities.topk(k)\n        relevant = labels[top_k_indices].float()\n        return (relevant.sum() / k).mean().item()\n    \n    def mean_reciprocal_rank(self, similarities, labels):\n        \"\"\"Calculate MRR\"\"\"\n        ranks = torch.where(labels[similarities.argsort(descending=True)])[0] + 1\n        return (1.0 / ranks.float()).mean().item()\n    \n    def compute_metrics(self, embeddings1, embeddings2, labels):\n        \"\"\"Compute all validation metrics\"\"\"\n        # Compute similarity matrix\n        similarities = F.cosine_similarity(embeddings1.unsqueeze(1), \n                                        embeddings2.unsqueeze(0), dim=2)\n        \n        metrics = {\n            'mrr': self.mean_reciprocal_rank(similarities, labels)\n        }\n        \n        for k in self.k_values:\n            metrics[f'p@{k}'] = self.precision_at_k(similarities, labels, k)\n            \n        return metrics\n\ndef validate(model, val_loader, criterion, metrics, device):\n    \"\"\"Validation step\"\"\"\n    model.eval()\n    total_loss = 0\n    all_emb1, all_emb2, all_labels = [], [], []\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            # Forward pass\n            emb1, emb2 = model(batch)\n            \n            # Compute loss\n            loss = criterion(emb1, emb2, batch['label'])\n            total_loss += loss.item()\n            \n            # Store embeddings and labels for metrics\n            all_emb1.append(emb1)\n            all_emb2.append(emb2)\n            all_labels.append(batch['label'])\n    \n    # Concatenate all batches\n    all_emb1 = torch.cat(all_emb1)\n    all_emb2 = torch.cat(all_emb2)\n    all_labels = torch.cat(all_labels)\n    \n    # Compute metrics\n    validation_metrics = metrics.compute_metrics(all_emb1, all_emb2, all_labels)\n    validation_metrics['loss'] = total_loss / len(val_loader)\n    \n    return validation_metrics","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def train_model(model, train_loader, val_loader, config):\n    \"\"\"Training with hyperparameter configuration\"\"\"\n    criterion = ContrastiveLoss(margin=config['margin'])\n    optimizer = torch.optim.AdamW(model.parameters(), \n                                lr=config['learning_rate'],\n                                weight_decay=config['weight_decay'])\n    \n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.5, patience=2, verbose=True\n    )\n    \n    metrics = ValidationMetrics(k_values=[1, 5, 10])\n    best_val_loss = float('inf')\n    patience = config['patience']\n    patience_counter = 0\n    \n    for epoch in range(config['epochs']):\n        # Training\n        train_loss = train_epoch(model, train_loader, criterion, optimizer, config['device'])\n        \n        # Validation\n        val_metrics = validate(model, val_loader, criterion, metrics, config['device'])\n        \n        # Learning rate scheduling\n        scheduler.step(val_metrics['loss'])\n        \n        # Early stopping\n        if val_metrics['loss'] < best_val_loss:\n            best_val_loss = val_metrics['loss']\n            patience_counter = 0\n            # Save best model\n            torch.save(model.state_dict(), 'best_model.pt')\n        else:\n            patience_counter += 1\n            if patience_counter >= patience:\n                print(f\"Early stopping at epoch {epoch}\")\n                break\n        \n        # Print metrics\n        print(f\"Epoch {epoch}:\")\n        print(f\"Train Loss: {train_loss:.4f}\")\n        print(f\"Val Loss: {val_metrics['loss']:.4f}\")\n        print(f\"Val MRR: {val_metrics['mrr']:.4f}\")\n        for k in metrics.k_values:\n            print(f\"Val P@{k}: {val_metrics[f'p@{k}']:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom transformers import AutoTokenizer\nimport os\nfrom datetime import datetime\n\ndef setup_training(config):\n    # Set random seeds for reproducibility\n    torch.manual_seed(config['seed'])\n    torch.cuda.manual_seed(config['seed'])\n    \n    # Initialize tokenizer\n    tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n    \n    # Create datasets\n    train_dataset = TrialDataset(balanced_train_df, tokenizer, max_length=config['max_length'])\n    val_dataset = TrialDataset(val_df, tokenizer, max_length=config['max_length'])\n    \n    # Create dataloaders\n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config['batch_size'],\n        shuffle=True,\n        num_workers=config['num_workers']\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config['batch_size'],\n        shuffle=False,\n        num_workers=config['num_workers']\n    )\n    \n    # Initialize model\n    model = HybridEncoder(\n        model_name=config['model_name'],\n        text_dim=config['text_dim'],\n        tfidf_dim=config['tfidf_dim'],\n        numeric_dim=config['numeric_dim']\n    ).to(config['device'])\n    \n    return model, train_loader, val_loader\n\ndef save_checkpoint(model, optimizer, epoch, val_metrics, checkpoint_dir):\n    \"\"\"Save model checkpoint\"\"\"\n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    checkpoint_path = os.path.join(\n        checkpoint_dir, \n        f'checkpoint_epoch_{epoch}_{timestamp}.pt'\n    )\n    \n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'val_metrics': val_metrics,\n    }, checkpoint_path)\n    \n    return checkpoint_path\n\nimport json\nimport pandas as pd\nfrom pathlib import Path\n\nclass MetricLogger:\n    def __init__(self, log_dir):\n        self.log_dir = Path(log_dir)\n        self.log_dir.mkdir(exist_ok=True)\n        \n        # Initialize containers for metrics\n        self.metrics = {\n            'train_loss': [],\n            'val_loss': [],\n            'val_mrr': [],\n            'learning_rate': [],\n            'epoch': []\n        }\n        # Add P@K metrics\n        for k in [1, 5, 10]:\n            self.metrics[f'val_p@{k}'] = []\n            \n    def log_metrics(self, epoch, train_loss, val_metrics, current_lr):\n        \"\"\"Log metrics for one epoch\"\"\"\n        self.metrics['epoch'].append(epoch)\n        self.metrics['train_loss'].append(train_loss)\n        self.metrics['val_loss'].append(val_metrics['loss'])\n        self.metrics['val_mrr'].append(val_metrics['mrr'])\n        self.metrics['learning_rate'].append(current_lr)\n        \n        # Log P@K metrics\n        for k in [1, 5, 10]:\n            self.metrics[f'val_p@{k}'].append(val_metrics[f'p@{k}'])\n    \n    def save_metrics(self):\n        \"\"\"Save metrics to files\"\"\"\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        \n        # Save as CSV\n        df = pd.DataFrame(self.metrics)\n        csv_path = self.log_dir / f'metrics_{timestamp}.csv'\n        df.to_csv(csv_path, index=False)\n        \n        # Save as JSON\n        json_path = self.log_dir / f'metrics_{timestamp}.json'\n        with open(json_path, 'w') as f:\n            json.dump(self.metrics, f, indent=4)\n        \n        return csv_path, json_path\n\ndef train_model(model, train_loader, val_loader, config):\n    \"\"\"Training with metric logging\"\"\"\n    # Initialize metric logger\n    logger = MetricLogger(config['log_dir'])\n    \n    criterion = ContrastiveLoss(margin=config['margin'])\n    optimizer = torch.optim.AdamW(\n        model.parameters(),\n        lr=config['learning_rate'],\n        weight_decay=config['weight_decay']\n    )\n    \n    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n        optimizer, mode='min', factor=0.5, patience=2, verbose=True\n    )\n    \n    metrics = ValidationMetrics(k_values=[1, 5, 10])\n    best_val_loss = float('inf')\n    best_model_path = None\n    \n    for epoch in range(config['epochs']):\n        print(f\"\\nEpoch {epoch+1}/{config['epochs']}\")\n        \n        # Training phase\n        train_loss = train_epoch(model, train_loader, criterion, optimizer, config['device'])\n        \n        # Validation phase\n        val_metrics = validate(model, val_loader, criterion, metrics, config['device'])\n        \n        # Log metrics\n        current_lr = optimizer.param_groups[0]['lr']\n        logger.log_metrics(epoch, train_loss, val_metrics, current_lr)\n        \n        # Learning rate scheduling\n        scheduler.step(val_metrics['loss'])\n        \n        # Save checkpoint\n        checkpoint_path = save_checkpoint(\n            model, optimizer, epoch, val_metrics, config['checkpoint_dir']\n        )\n        \n        # Save best model\n        if val_metrics['loss'] < best_val_loss:\n            best_val_loss = val_metrics['loss']\n            if best_model_path and os.path.exists(best_model_path):\n                os.remove(best_model_path)\n            best_model_path = os.path.join(config['checkpoint_dir'], 'best_model.pt')\n            torch.save(model.state_dict(), best_model_path)\n        \n        # Print metrics\n        print(f\"Train Loss: {train_loss:.4f}\")\n        print(f\"Validation Loss: {val_metrics['loss']:.4f}\")\n        print(f\"Validation MRR: {val_metrics['mrr']:.4f}\")\n        for k in metrics.k_values:\n            print(f\"Validation P@{k}: {val_metrics[f'p@{k}']:.4f}\")\n        \n        # Early stopping check\n        if val_metrics['loss'] > best_val_loss * (1 + config['early_stopping_threshold']):\n            config['patience_counter'] += 1\n            if config['patience_counter'] >= config['patience']:\n                print(\"Early stopping triggered\")\n                break\n        else:\n            config['patience_counter'] = 0\n    \n    # Save final metrics\n    csv_path, json_path = logger.save_metrics()\n    print(f\"\\nMetrics saved to:\")\n    print(f\"CSV: {csv_path}\")\n    print(f\"JSON: {json_path}\")\n\n# Update config with log directory\nconfig.update({\n    'log_dir': 'training_logs'\n})\n\n\n# Configuration\nconfig = {\n    'model_name': 'allenai/scibert_scivocab_uncased',\n    'text_dim': 768,\n    'tfidf_dim': 5000,  # Adjust based on your TF-IDF vector size\n    'numeric_dim': 3,\n    'max_length': 512,\n    'batch_size': 16,\n    'num_workers': 4,\n    'learning_rate': 2e-5,\n    'weight_decay': 0.01,\n    'margin': 1.0,\n    'epochs': 10,\n    'patience': 3,\n    'early_stopping_threshold': 0.01,\n    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n    'checkpoint_dir': 'checkpoints',\n    'seed': 42,\n    'patience_counter': 0\n}\n\n# Run training\nif __name__ == \"__main__\":\n    print(\"Initializing training...\")\n    model, train_loader, val_loader = setup_training(config)\n    \n    print(\"Starting training...\")\n    train_model(model, train_loader, val_loader, config)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel\nimport os\nimport numpy as np\nfrom datetime import datetime\nimport json\nimport pandas as pd\nfrom pathlib import Path\nfrom tqdm import tqdm\n\nclass TrialDataset(Dataset):\n    def __init__(self, df, tokenizer, max_length=512):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        \n        # Combine text fields\n        text1 = f\"{row['Study Title_Cleaned_1']} {row['Primary Outcome Measures_Cleaned_1']} {row['criteria_Cleaned_1']}\"\n        text2 = f\"{row['Study Title_Cleaned_2']} {row['Primary Outcome Measures_Cleaned_2']} {row['criteria_Cleaned_2']}\"\n        \n        # Tokenize texts\n        encoded1 = self.tokenizer(\n            text1,\n            truncation=True,\n            max_length=self.max_length,\n            padding='max_length',\n            return_tensors='pt'\n        )\n        \n        encoded2 = self.tokenizer(\n            text2,\n            truncation=True,\n            max_length=self.max_length,\n            padding='max_length',\n            return_tensors='pt'\n        )\n        \n        # Prepare numeric features\n        numeric1 = torch.tensor([\n            row['completeness_score_1'],\n            row['Secondary_Outcome_Missing_1'],\n            row['Primary_Outcome_Missing_1']\n        ], dtype=torch.float)\n        \n        numeric2 = torch.tensor([\n            row['completeness_score_2'],\n            row['Secondary_Outcome_Missing_2'],\n            row['Primary_Outcome_Missing_2']\n        ], dtype=torch.float)\n        \n        return {\n            'input_ids1': encoded1['input_ids'].squeeze(),\n            'attention_mask1': encoded1['attention_mask'].squeeze(),\n            'input_ids2': encoded2['input_ids'].squeeze(),\n            'attention_mask2': encoded2['attention_mask'].squeeze(),\n            'numeric1': numeric1,\n            'numeric2': numeric2,\n            'label': torch.tensor(row['label'], dtype=torch.float)\n        }\n\nclass ContrastiveLoss(nn.Module):\n    def __init__(self, margin=1.0):\n        super(ContrastiveLoss, self).__init__()\n        self.margin = margin\n        \n    def forward(self, emb1, emb2, label):\n        distance = F.pairwise_distance(emb1, emb2)\n        loss = torch.mean((1 - label) * torch.pow(distance, 2) + \n                         label * torch.pow(torch.clamp(self.margin - distance, min=0.0), 2))\n        return loss\n\nclass ValidationMetrics:\n    def __init__(self, k_values=[1, 5, 10]):\n        self.k_values = k_values\n    \n    def precision_at_k(self, similarities, labels, k):\n        _, top_k_indices = similarities.topk(k)\n        relevant = labels[top_k_indices].float()\n        return (relevant.sum() / k).mean().item()\n    \n    def mean_reciprocal_rank(self, similarities, labels):\n        ranks = torch.where(labels[similarities.argsort(descending=True)])[0] + 1\n        return (1.0 / ranks.float()).mean().item()\n    \n    def compute_metrics(self, embeddings1, embeddings2, labels):\n        similarities = F.cosine_similarity(embeddings1.unsqueeze(1), \n                                        embeddings2.unsqueeze(0), dim=2)\n        \n        metrics = {\n            'mrr': self.mean_reciprocal_rank(similarities, labels)\n        }\n        \n        for k in self.k_values:\n            metrics[f'p@{k}'] = self.precision_at_k(similarities, labels, k)\n            \n        return metrics\n\nclass MetricLogger:\n    def __init__(self, log_dir):\n        self.log_dir = Path(log_dir)\n        self.log_dir.mkdir(exist_ok=True)\n        \n        self.metrics = {\n            'train_loss': [],\n            'val_loss': [],\n            'val_mrr': [],\n            'learning_rate': [],\n            'epoch': []\n        }\n        for k in [1, 5, 10]:\n            self.metrics[f'val_p@{k}'] = []\n            \n    def log_metrics(self, epoch, train_loss, val_metrics, current_lr):\n        self.metrics['epoch'].append(epoch)\n        self.metrics['train_loss'].append(train_loss)\n        self.metrics['val_loss'].append(val_metrics['loss'])\n        self.metrics['val_mrr'].append(val_metrics['mrr'])\n        self.metrics['learning_rate'].append(current_lr)\n        \n        for k in [1, 5, 10]:\n            self.metrics[f'val_p@{k}'].append(val_metrics[f'p@{k}'])\n    \n    def save_metrics(self):\n        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n        \n        df = pd.DataFrame(self.metrics)\n        csv_path = self.log_dir / f'metrics_{timestamp}.csv'\n        df.to_csv(csv_path, index=False)\n        \n        json_path = self.log_dir / f'metrics_{timestamp}.json'\n        with open(json_path, 'w') as f:\n            json.dump(self.metrics, f, indent=4)\n        \n        return csv_path, json_path\n\ndef train_epoch(model, train_loader, criterion, optimizer, device):\n    model.train()\n    total_loss = 0\n    \n    for batch in tqdm(train_loader, desc='Training'):\n        try:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            \n            optimizer.zero_grad()\n            emb1, emb2 = model(batch)\n            loss = criterion(emb1, emb2, batch['label'])\n            \n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n        except RuntimeError as e:\n            print(f\"Error in batch: {str(e)}\")\n            continue\n            \n    return total_loss / len(train_loader)\n\ndef validate(model, val_loader, criterion, metrics, device):\n    model.eval()\n    total_loss = 0\n    all_emb1, all_emb2, all_labels = [], [], []\n    \n    with torch.no_grad():\n        for batch in val_loader:\n            batch = {k: v.to(device) for k, v in batch.items()}\n            emb1, emb2 = model(batch)\n            loss = criterion(emb1, emb2, batch['label'])\n            \n            total_loss += loss.item()\n            all_emb1.append(emb1.cpu())\n            all_emb2.append(emb2.cpu())\n            all_labels.append(batch['label'].cpu())\n            \n            torch.cuda.empty_cache()\n    \n    all_emb1 = torch.cat(all_emb1)\n    all_emb2 = torch.cat(all_emb2)\n    all_labels = torch.cat(all_labels)\n    \n    validation_metrics = metrics.compute_metrics(all_emb1, all_emb2, all_labels)\n    validation_metrics['loss'] = total_loss / len(val_loader)\n    \n    return validation_metrics\n\ndef setup_training(config):\n    torch.manual_seed(config['seed'])\n    torch.cuda.manual_seed(config['seed'])\n    \n    tokenizer = AutoTokenizer.from_pretrained(config['model_name'])\n    \n    train_dataset = TrialDataset(balanced_train_df, tokenizer, max_length=config['max_length'])\n    val_dataset = TrialDataset(val_df, tokenizer, max_length=config['max_length'])\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config['batch_size'],\n        shuffle=True,\n        num_workers=config['num_workers']\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config['batch_size'],\n        shuffle=False,\n        num_workers=config['num_workers']\n    )\n    \n    model = HybridEncoder(\n        model_name=config['model_name'],\n        text_dim=config['text_dim'],\n        tfidf_dim=config['tfidf_dim'],\n        numeric_dim=config['numeric_dim']\n    ).to(config['device'])\n    \n    return model, train_loader, val_loader\n\ndef save_checkpoint(model, optimizer, epoch, val_metrics, checkpoint_dir):\n    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n    checkpoint_path = os.path.join(\n        checkpoint_dir, \n        f'checkpoint_epoch_{epoch}_{timestamp}.pt'\n    )\n    \n    torch.save({\n        'epoch': epoch,\n        'model_state_dict': model.state_dict(),\n        'optimizer_state_dict': optimizer.state_dict(),\n        'val_metrics': val_metrics,\n    }, checkpoint_path)\n    \n    return checkpoint_path\n\ndef train_model(model, train_loader, val_loader, config):\n    try:\n        logger = MetricLogger(config['log_dir'])\n        \n        criterion = ContrastiveLoss(margin=config['margin'])\n        optimizer = torch.optim.AdamW(\n            model.parameters(),\n            lr=config['learning_rate'],\n            weight_decay=config['weight_decay']\n        )\n        \n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='min', factor=0.5, patience=2, verbose=True\n        )\n        \n        metrics = ValidationMetrics(k_values=[1, 5, 10])\n        best_val_loss = float('inf')\n        best_model_path = None\n        \n        for epoch in range(config['epochs']):\n            print(f\"\\nEpoch {epoch+1}/{config['epochs']}\")\n            \n            train_loss = train_epoch(model, train_loader, criterion, optimizer, config['device'])\n            val_metrics = validate(model, val_loader, criterion, metrics, config['device'])\n            \n            current_lr = optimizer.param_groups[0]['lr']\n            logger.log_metrics(epoch, train_loss, val_metrics, current_lr)\n            \n            scheduler.step(val_metrics['loss'])\n            \n            checkpoint_path = save_checkpoint(\n                model, optimizer, epoch, val_metrics, config['checkpoint_dir']\n            )\n            \n            if val_metrics['loss'] < best_val_loss:\n                best_val_loss = val_metrics['loss']\n                if best_model_path and os.path.exists(best_model_path):\n                    os.remove(best_model_path)\n                best_model_path = os.path.join(config['checkpoint_dir'], 'best_model.pt')\n                torch.save(model.state_dict(), best_model_path)\n            \n            print(f\"Train Loss: {train_loss:.4f}\")\n            print(f\"Validation Loss: {val_metrics['loss']:.4f}\")\n            print(f\"Validation MRR: {val_metrics['mrr']:.4f}\")\n            for k in metrics.k_values:\n                print(f\"Validation P@{k}: {val_metrics[f'p@{k}']:.4f}\")\n            \n            if val_metrics['loss'] > best_val_loss * (1 + config['early_stopping_threshold']):\n                config['patience_counter'] += 1\n                if config['patience_counter'] >= config['patience']:\n                    print(\"Early stopping triggered\")\n                    break\n            else:\n                config['patience_counter'] = 0\n        \n        csv_path, json_path = logger.save_metrics()\n        print(f\"\\nMetrics saved to:\")\n        print(f\"CSV: {csv_path}\")\n        print(f\"JSON: {json_path}\")\n        \n    except Exception as e:\n        print(f\"Error during training: {str(e)}\")\n        if 'model' in locals() and 'optimizer' in locals():\n            save_checkpoint(model, optimizer, epoch, val_metrics, config['checkpoint_dir'])\n        raise e\n\nconfig = {\n    'model_name': 'allenai/scibert_scivocab_uncased',\n    'text_dim': 768,\n    'tfidf_dim': 5000,\n    'numeric_dim': 3,\n    'max_length': 512,\n    'batch_size': 16,\n    'num_workers': 4,\n    'learning_rate': 2e-5,\n    'weight_decay': 0.01,\n    'margin': 1.0,\n    'epochs': 10,\n    'patience': 3,\n    'early_stopping_threshold': 0.01,\n    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n    'checkpoint_dir': 'checkpoints',\n    'log_dir': 'training_logs',\n    'seed': 42,\n    'patience_counter': 0,\n    'grad_clip': 1.0\n}\n\nif __name__ == \"__main__\":\n    print(\"Initializing training...\")\n    model, train_loader, val_loader = setup_training(config)\n    \n    print(\"Starting training...\")\n    train_model(model, train_loader, val_loader, config)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}